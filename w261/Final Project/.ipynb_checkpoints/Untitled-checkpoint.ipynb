{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import time\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler, StandardScaler, VectorIndexer, Normalizer\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, BinaryLogisticRegressionSummary\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]\n",
    "\n",
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"hw5_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# Define the schema prior to loading the data\n",
    "schema = StructType([StructField(\"label\", IntegerType(), True),\n",
    "                     StructField(\"I1\", IntegerType(), True),\n",
    "                     StructField(\"I2\", IntegerType(), True),\n",
    "                     StructField(\"I3\", IntegerType(), True),\n",
    "                     StructField(\"I4\", IntegerType(), True),\n",
    "                     StructField(\"I5\", IntegerType(), True),\n",
    "                     StructField(\"I6\", IntegerType(), True),\n",
    "                     StructField(\"I7\", IntegerType(), True),\n",
    "                     StructField(\"I8\", IntegerType(), True),\n",
    "                     StructField(\"I9\", IntegerType(), True),\n",
    "                     StructField(\"I10\", IntegerType(), True),\n",
    "                     StructField(\"I11\", IntegerType(), True),\n",
    "                     StructField(\"I12\", IntegerType(), True),\n",
    "                     StructField(\"I13\", IntegerType(), True),\n",
    "                     StructField(\"C1\", StringType(), True),\n",
    "                     StructField(\"C2\", StringType(), True),\n",
    "                     StructField(\"C3\", StringType(), True),\n",
    "                     StructField(\"C4\", StringType(), True),\n",
    "                     StructField(\"C5\", StringType(), True),\n",
    "                     StructField(\"C6\", StringType(), True),\n",
    "                     StructField(\"C7\", StringType(), True),\n",
    "                     StructField(\"C8\", StringType(), True),\n",
    "                     StructField(\"C9\", StringType(), True),\n",
    "                     StructField(\"C10\", StringType(), True),\n",
    "                     StructField(\"C11\", StringType(), True),\n",
    "                     StructField(\"C12\", StringType(), True),\n",
    "                     StructField(\"C13\", StringType(), True),\n",
    "                     StructField(\"C14\", StringType(), True),\n",
    "                     StructField(\"C15\", StringType(), True),\n",
    "                     StructField(\"C16\", StringType(), True),\n",
    "                     StructField(\"C17\", StringType(), True),\n",
    "                     StructField(\"C18\", StringType(), True),\n",
    "                     StructField(\"C19\", StringType(), True),\n",
    "                     StructField(\"C20\", StringType(), True),\n",
    "                     StructField(\"C21\", StringType(), True),\n",
    "                     StructField(\"C22\", StringType(), True),\n",
    "                     StructField(\"C23\", StringType(), True),\n",
    "                     StructField(\"C24\", StringType(), True),\n",
    "                     StructField(\"C25\", StringType(), True),\n",
    "                     StructField(\"C26\", StringType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load toy data into dataframe\n",
    "toy_df = spark.read.parquet(\"toyData/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just some code to get only the numeric numbers for training. Won't be using this for the official notebook\n",
    "toy_rdd = toy_df.rdd.map(tuple)\n",
    "toy_RDD = toy_rdd.map(lambda line: (line[0],(line[1:14]))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>[1.0, 17.0, 3.0, 6.0, 5.0, 6.0, 1.0, 5.0, 6.0,...</td>\n",
       "      <td>[0.0, 23.0, 47.0, 6.0, 13044.0, 2546.0, 0.0, 7...</td>\n",
       "      <td>[-999.0, 0.0, 1.0, 2.0, 20.0, -999.0, 0.0, 2.0...</td>\n",
       "      <td>[0.0, 3.0, 13.0, 1.0, 2940.0, 83.0, 1.0, 16.0,...</td>\n",
       "      <td>[1.0, 0.0, 5.0, 3.0, 171.0, 34.0, 3.0, 34.0, 6...</td>\n",
       "      <td>[-999.0, -1.0, -999.0, -999.0, 2975.0, 1.0, 14...</td>\n",
       "      <td>[-999.0, 2.0, 1.0, 3.0, 3031.0, 76.0, 1.0, 3.0...</td>\n",
       "      <td>[1.0, 4.0, 19.0, 17.0, 36.0, 7.0, 6.0, 22.0, 9...</td>\n",
       "      <td>[-999.0, -1.0, -999.0, -999.0, 8740.0, 12.0, 1...</td>\n",
       "      <td>[-999.0, 0.0, 7.0, 18.0, 3424.0, 22.0, 1.0, 21...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-999.0, 1.0, 3.0, 3.0, 109391.0, -999.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 2.0, 3.0, 1344.0, 5.0, 30.0, 7.0, 3...</td>\n",
       "      <td>[0.0, 68.0, 16.0, 3.0, 3735.0, 64.0, 1.0, 3.0,...</td>\n",
       "      <td>(-999.0, 0.0, 16.0, 8.0, 0.0, -999.0, 0.0, 7.0...</td>\n",
       "      <td>[-999.0, 1.0, 4.0, 4.0, 1837.0, 9.0, 2.0, 4.0,...</td>\n",
       "      <td>[0.0, 0.0, 4.0, -999.0, 1573.0, 42.0, 14.0, 8....</td>\n",
       "      <td>[5.0, 297.0, 5.0, 3.0, 8.0, 1.0, 34.0, 3.0, 14...</td>\n",
       "      <td>[-999.0, 1.0, 4.0, 2.0, 66163.0, -999.0, 0.0, ...</td>\n",
       "      <td>[-999.0, -1.0, 17.0, 6.0, 31979.0, 94.0, 1.0, ...</td>\n",
       "      <td>[-999.0, 31.0, 1.0, -999.0, 28527.0, -999.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0   \\\n",
       "features  [1.0, 17.0, 3.0, 6.0, 5.0, 6.0, 1.0, 5.0, 6.0,...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         1   \\\n",
       "features  [0.0, 23.0, 47.0, 6.0, 13044.0, 2546.0, 0.0, 7...   \n",
       "label                                                     1   \n",
       "\n",
       "                                                         2   \\\n",
       "features  [-999.0, 0.0, 1.0, 2.0, 20.0, -999.0, 0.0, 2.0...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         3   \\\n",
       "features  [0.0, 3.0, 13.0, 1.0, 2940.0, 83.0, 1.0, 16.0,...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         4   \\\n",
       "features  [1.0, 0.0, 5.0, 3.0, 171.0, 34.0, 3.0, 34.0, 6...   \n",
       "label                                                     1   \n",
       "\n",
       "                                                         5   \\\n",
       "features  [-999.0, -1.0, -999.0, -999.0, 2975.0, 1.0, 14...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         6   \\\n",
       "features  [-999.0, 2.0, 1.0, 3.0, 3031.0, 76.0, 1.0, 3.0...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         7   \\\n",
       "features  [1.0, 4.0, 19.0, 17.0, 36.0, 7.0, 6.0, 22.0, 9...   \n",
       "label                                                     1   \n",
       "\n",
       "                                                         8   \\\n",
       "features  [-999.0, -1.0, -999.0, -999.0, 8740.0, 12.0, 1...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         9   \\\n",
       "features  [-999.0, 0.0, 7.0, 18.0, 3424.0, 22.0, 1.0, 21...   \n",
       "label                                                     0   \n",
       "\n",
       "                                ...                          \\\n",
       "features                        ...                           \n",
       "label                           ...                           \n",
       "\n",
       "                                                         15  \\\n",
       "features  [-999.0, 1.0, 3.0, 3.0, 109391.0, -999.0, 0.0,...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         16  \\\n",
       "features  [0.0, 0.0, 2.0, 3.0, 1344.0, 5.0, 30.0, 7.0, 3...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         17  \\\n",
       "features  [0.0, 68.0, 16.0, 3.0, 3735.0, 64.0, 1.0, 3.0,...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         18  \\\n",
       "features  (-999.0, 0.0, 16.0, 8.0, 0.0, -999.0, 0.0, 7.0...   \n",
       "label                                                     1   \n",
       "\n",
       "                                                         19  \\\n",
       "features  [-999.0, 1.0, 4.0, 4.0, 1837.0, 9.0, 2.0, 4.0,...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         20  \\\n",
       "features  [0.0, 0.0, 4.0, -999.0, 1573.0, 42.0, 14.0, 8....   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         21  \\\n",
       "features  [5.0, 297.0, 5.0, 3.0, 8.0, 1.0, 34.0, 3.0, 14...   \n",
       "label                                                     1   \n",
       "\n",
       "                                                         22  \\\n",
       "features  [-999.0, 1.0, 4.0, 2.0, 66163.0, -999.0, 0.0, ...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         23  \\\n",
       "features  [-999.0, -1.0, 17.0, 6.0, 31979.0, 94.0, 1.0, ...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                         24  \n",
       "features  [-999.0, 31.0, 1.0, -999.0, 28527.0, -999.0, 0...  \n",
       "label                                                     0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13'],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "toy_df_transformed = assembler.transform(toy_df)\n",
    "toy_df_transformed = toy_df_transformed.select('features','label')\n",
    "pd.DataFrame(toy_df_transformed.take(30), columns=toy_df_transformed.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_df = spark.createDataFrame(\n",
    "    [(1.0, 1, 1, 1),\n",
    "     (1.0, 5, 2, 2),\n",
    "     (0.0, 3, 0, 3)],\n",
    "    [\"label\", \"page_num\", \"hour\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, (1, 1, 1)), (1.0, (5, 2, 2)), (0.0, (3, 0, 3))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_rdd = toy_df.rdd.map(tuple)\n",
    "toy_RDD = toy_rdd.map(lambda line: (line[0],(line[1:4]))).cache()\n",
    "toy_RDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toy_RDD will be the RDD used to train a logistic regression using the gradient descent method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "      <td>[5.0, 2.0, 2.0]</td>\n",
       "      <td>[3.0, 0.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0                1                2\n",
       "features  [1.0, 1.0, 1.0]  [5.0, 2.0, 2.0]  [3.0, 0.0, 3.0]\n",
       "label                   1                1                0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"page_num\", \"hour\", \"id\"],\n",
    "    outputCol=\"features\")\n",
    "toy_df_transformed = assembler.transform(toy_df)\n",
    "toy_df_transformed = toy_df_transformed.select('features','label')\n",
    "pd.DataFrame(toy_df_transformed.take(30), columns=toy_df_transformed.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toy_df_transformed will be the dataframe used to train a logistic regression using Spark ML's LogisticRegression() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLoss(dataRDD, W):\n",
    "    \"\"\"\n",
    "    Compute the Log Loss of our model.\n",
    "    Args:\n",
    "        dataRDD - each record is a tuple of (y, features_array)\n",
    "        W       - (array) model coefficients\n",
    "    \"\"\"\n",
    "    # Add 1 to the front of the predictors array\n",
    "    # Note that the b value has to be added to the front of our theta array\n",
    "    augmentedData = dataRDD.map(lambda x: (x[0], np.append([1.0], x[1])))\n",
    "\n",
    "    def LogLossPerRow(line):\n",
    "        # Calculate the log loss for each row of the data in parallel\n",
    "        actual_y, features = line\n",
    "        predicted_y = np.dot(np.transpose(W),features)\n",
    "        prob = 1.0/(1.0 + np.exp(-1.0*predicted_y))\n",
    "        # Output is -[ylog(prob) + (1-y)log(1-prob)]\n",
    "        yield -1.0*(actual_y*np.log(prob) + (1-actual_y)*np.log(1-prob))\n",
    "    \n",
    "    loss = augmentedData.flatMap(LogLossPerRow).mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test our LogLoss function by setting b to the mean of the our label values and all our predictors to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.24\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of all our label values\n",
    "meanQuality = toy_RDD.map(lambda x: x[0]).mean()\n",
    "print(f\"Mean: {meanQuality}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the baseline model so that b is the mean we calculated and all other features are 0\n",
    "#BASELINE = np.append([meanQuality],[0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "BASELINE = np.append([meanQuality],[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model loss: 0.6365923090742943\n"
     ]
    }
   ],
   "source": [
    "# Compute the loss of the baseline model\n",
    "assert len(BASELINE) == len(toy_RDD.take(1)[0][1]) + 1, \"Double check model dimensions\"\n",
    "print(f\"Baseline model loss: {LogLoss(toy_RDD, BASELINE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 ones and 1 zeros in the label column of our dataset\n",
      "The loss of the baseline model through manual calculation is 0.6365923090742943\n"
     ]
    }
   ],
   "source": [
    "# Verify if our result is correct or not\n",
    "\n",
    "# Count how many 1's and 0's we have in our label\n",
    "ones = toy_RDD.map(lambda line: 1 if line[0] == 1 else 0).sum()\n",
    "zeros = toy_RDD.count() - ones\n",
    "print(\"There are {} ones and {} zeros in the label column of our dataset\".format(ones, zeros))\n",
    "\n",
    "# Calculate the LogLoss in our example case\n",
    "loss = (ones*np.log(1/(1.0 + np.exp(-1.0*meanQuality))) + zeros*np.log(1.0 - 1.0/(1.0 + np.exp(-1.0*meanQuality))))/-3.0\n",
    "print(\"The loss of the baseline model through manual calculation is {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the results of our LogLoss() function is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code calculates the 3 different gradients with and without regularization\n",
    "# Then it updates the model (w) and outputs the new model\n",
    "def GDUpdate_wReg(dataRDD, W, learningRate = 0.1, regType = None, regParam = 0.1):\n",
    "    \"\"\"\n",
    "    Perform one gradient descent step/update with ridge or lasso regularization.\n",
    "    Args:\n",
    "        dataRDD - tuple of (y, features_array)\n",
    "        W       - (array) model coefficients with intercept at index 0\n",
    "        learningRate - (float) defaults to 0.1\n",
    "        regType - (str) 'ridge' or 'lasso', defaults to None\n",
    "        regParam - (float) regularization term coefficient\n",
    "    Returns:\n",
    "        model   - (array) updated coefficients, intercept still at index 0\n",
    "    \"\"\"\n",
    "    # augmented data\n",
    "    augmentedData = dataRDD.map(lambda x: (x[0], np.append([1.0], x[1])))\n",
    "    \n",
    "    new_model = None\n",
    "\n",
    "    def GradientPerRow(line):\n",
    "        # Calculates -y(1- 1/ 1+ exp( -ywx))x for each row\n",
    "        actual_y, features = line\n",
    "        predicted_y = np.dot(np.transpose(W),features)\n",
    "        prob = 1.0/(1.0 + np.exp(-1.0*predicted_y))\n",
    "        yield (prob - actual_y)*features\n",
    "        \n",
    "    # Use the same way as before to find the first component of the gradient function\n",
    "    grad = augmentedData.flatMap(GradientPerRow).sum()\n",
    "    \n",
    "    # Take out the bias stored in index 0 of W\n",
    "    model = W[1:]\n",
    "    \n",
    "    # Figure out the regulation component\n",
    "    if regType == None:\n",
    "        pass\n",
    "        \n",
    "    elif regType == 'lasso':\n",
    "        reg_comp = regParam*np.sign(model)\n",
    "        # Update the gradient function by taking the regularization component into consideration\n",
    "        grad = grad + np.append(0,reg_comp)\n",
    "                \n",
    "    elif regType == 'ridge':\n",
    "        reg_comp = regParam*model\n",
    "        # Update the gradient function by taking the regularization component into consideration\n",
    "        grad = grad + np.append(0,reg_comp)\n",
    "    \n",
    "    new_model = W - (learningRate*grad)\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code performs the Gradient Descent iterations \n",
    "def GradientDescent_wReg(trainRDD, wInit, nSteps = 20, learningRate = 0.1,\n",
    "                         regType = None, regParam = 0.1, verbose = False):\n",
    "    \"\"\"\n",
    "    Perform nSteps iterations of regularized gradient descent and \n",
    "    track loss on a test and train set. Return lists of\n",
    "    test/train loss and the models themselves.\n",
    "    \"\"\"\n",
    "    # initialize lists to track model performance\n",
    "    train_history, model_history = [], []\n",
    "    \n",
    "    # perform n updates & compute test and train loss after each update\n",
    "    model = wInit\n",
    "    for idx in range(nSteps):  \n",
    "        # update the model\n",
    "        model = GDUpdate_wReg(trainRDD, model, learningRate, regType, regParam)\n",
    "        \n",
    "        # keep track of test/train loss for plotting\n",
    "        train_history.append(LogLoss(trainRDD, model))\n",
    "        model_history.append(model)\n",
    "        \n",
    "        # console output if desired\n",
    "        if verbose:\n",
    "            print(\"----------\")\n",
    "            print(f\"STEP: {idx+1}\")\n",
    "            print(f\"training loss: {LogLoss(trainRDD, model)}\")\n",
    "            print(f\"Model: {[round(w,3) for w in model]}\")\n",
    "    return train_history, model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 50 iterations\n",
    "meanQuality = toy_RDD.map(lambda x: x[0]).mean()\n",
    "wInit = np.append([meanQuality],[0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "#wInit = np.append([meanQuality],[0,0,0])\n",
    "\n",
    "start = time.time()\n",
    "results = GradientDescent_wReg(toy_RDD, wInit, nSteps = 50, learningRate = 1.0, \n",
    "                                     regType=None, regParam = 5.0, verbose = False )\n",
    "print(f\"\\n... trained {len(results[1])} iterations in {time.time() - start} seconds\")\n",
    "print(\"The final log loss is: {}\".format(results[0][-1]))\n",
    "print(\"The coefficients are: {}\".format(results[1][-1][1:]))\n",
    "print(\"The intercept is: {}\".format(results[1][-1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=50, regParam=0, standardization=False, fitIntercept=True)\n",
    "lrModel = lr.fit(toy_df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-1.536273002737445,19.1462705537368,-8.398210811732106]\n",
      "Intercept: 9.906884345546295\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
