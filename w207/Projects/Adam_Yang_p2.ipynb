{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll work with text data from newsgroup postings on a variety of topics. You'll train classifiers to distinguish between the topics based on the text of the posts. Whereas with digit classification, the input is relatively dense: a 28x28 matrix of pixels, many of which are non-zero, here we'll represent each document with a \"bag-of-words\" model. As you'll see, this makes the feature representation quite sparse -- only a few words of the total vocabulary are active in any given document. The bag-of-words assumption here is that the label depends only on the words; their order is not important.\n",
    "\n",
    "The SK-learn documentation on feature extraction will prove useful:\n",
    "http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but please prepare your own write-up and write your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamyang/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/adamyang/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, stripping out metadata so that we learn classifiers that only use textual features. By default, newsgroups data is split into train and test sets. We further split the test so we have a dev set. Note that we specify 4 categories to use for this project. If you remove the categories argument from the fetch function, you'll get all 20 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label shape: (2034,)\n",
      "test label shape: (677,)\n",
      "dev label shape: (676,)\n",
      "labels names: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)\n",
    "\n",
    "num_test = len(newsgroups_test.target)\n",
    "# Note to grader: I had to change the code here so that num_test/2 is an integer rather than a float.\n",
    "test_data, test_labels = newsgroups_test.data[int(num_test/2):], newsgroups_test.target[int(num_test/2):]\n",
    "dev_data, dev_labels = newsgroups_test.data[:int(num_test/2)], newsgroups_test.target[:int(num_test/2)]\n",
    "train_data, train_labels = newsgroups_train.data, newsgroups_train.target\n",
    "\n",
    "print ('training label shape:', train_labels.shape)\n",
    "print ('test label shape:', test_labels.shape)\n",
    "print ('dev label shape:', dev_labels.shape)\n",
    "print ('labels names:', newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) For each of the first 5 training examples, print the text of the message along with the label.\n",
    "\n",
    "[2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mText number 1 is:\u001b[0m\n",
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "\u001b[91m\u001b[1mThe label for this text is 1 and the label name is comp.graphics\u001b[0m\n",
      "\n",
      "\u001b[1mText number 2 is:\u001b[0m\n",
      "\n",
      "\n",
      "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
      "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
      "folks with him, children and all, to satisfy his delusional mania. Jim\n",
      "Jones, circa 1993.\n",
      "\n",
      "\n",
      "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
      "for centuries.\n",
      "\n",
      "\u001b[91m\u001b[1mThe label for this text is 3 and the label name is talk.religion.misc\u001b[0m\n",
      "\n",
      "\u001b[1mText number 3 is:\u001b[0m\n",
      "\n",
      " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
      "\n",
      "MB>                                                             So the\n",
      "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
      "\n",
      "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
      "\n",
      "Couldn't we just say periapsis or apoapsis?\n",
      "\n",
      " \n",
      "\n",
      "\u001b[91m\u001b[1mThe label for this text is 2 and the label name is sci.space\u001b[0m\n",
      "\n",
      "\u001b[1mText number 4 is:\u001b[0m\n",
      "I have a request for those who would like to see Charley Wingate\n",
      "respond to the \"Charley Challenges\" (and judging from my e-mail, there\n",
      "appear to be quite a few of you.)  \n",
      "\n",
      "It is clear that Mr. Wingate intends to continue to post tangential or\n",
      "unrelated articles while ingoring the Challenges themselves.  Between\n",
      "the last two re-postings of the Challenges, I noted perhaps a dozen or\n",
      "more posts by Mr. Wingate, none of which answered a single Challenge.  \n",
      "\n",
      "It seems unmistakable to me that Mr. Wingate hopes that the questions\n",
      "will just go away, and he is doing his level best to change the\n",
      "subject.  Given that this seems a rather common net.theist tactic, I\n",
      "would like to suggest that we impress upon him our desire for answers,\n",
      "in the following manner:\n",
      "\n",
      "1. Ignore any future articles by Mr. Wingate that do not address the\n",
      "Challenges, until he answers them or explictly announces that he\n",
      "refuses to do so.\n",
      "\n",
      "--or--\n",
      "\n",
      "2. If you must respond to one of his articles, include within it\n",
      "something similar to the following:\n",
      "\n",
      "    \"Please answer the questions posed to you in the Charley Challenges.\"\n",
      "\n",
      "Really, I'm not looking to humiliate anyone here, I just want some\n",
      "honest answers.  You wouldn't think that honesty would be too much to\n",
      "ask from a devout Christian, would you?  \n",
      "\n",
      "Nevermind, that was a rhetorical question.\n",
      "\n",
      "\u001b[91m\u001b[1mThe label for this text is 0 and the label name is alt.atheism\u001b[0m\n",
      "\n",
      "\u001b[1mText number 5 is:\u001b[0m\n",
      "AW&ST  had a brief blurb on a Manned Lunar Exploration confernce\n",
      "May 7th  at Crystal City Virginia, under the auspices of AIAA.\n",
      "\n",
      "Does anyone know more about this?  How much, to attend????\n",
      "\n",
      "Anyone want to go?\n",
      "\n",
      "\u001b[91m\u001b[1mThe label for this text is 2 and the label name is sci.space\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "# Class created to simply bold or add color to printed text.\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "def P1(num_examples=5):\n",
    "    \"\"\"\n",
    "    Input the number of examples you want to print. Output the text for each example,\n",
    "    along with the label number as well as the label name.\n",
    "    \"\"\"\n",
    "    for i in range(num_examples):\n",
    "        # Print text of example\n",
    "        print(\"{}Text number {} is:{}\\n{}\\n\".format(color.BOLD,i+1,color.END,train_data[i]))\n",
    "        # Print label number and label name for the text \n",
    "        print(\"{}{}The label for this text is {} and the label name is {}{}\\n\"\n",
    "              .format(color.RED,color.BOLD,train_labels[i],\n",
    "                      newsgroups_train.target_names[train_labels[i]],color.END))\n",
    "    \n",
    "### STUDENT END ###\n",
    "P1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Use CountVectorizer to turn the raw training text into feature vectors. You should use the fit_transform function, which makes 2 passes through the data: first it computes the vocabulary (\"fit\"), second it converts the raw text into feature vectors using the vocabulary (\"transform\").\n",
    "\n",
    "The vectorizer has a lot of options. To get familiar with some of them, write code to answer these questions:\n",
    "\n",
    "a. The output of the transform (also of fit_transform) is a sparse matrix: http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html. What is the size of the vocabulary? What is the average number of non-zero features per example? What fraction of the entries in the matrix are non-zero? Hint: use \"nnz\" and \"shape\" attributes.\n",
    "\n",
    "b. What are the 0th and last feature strings (in alphabetical order)? Hint: use the vectorizer's get_feature_names function.\n",
    "\n",
    "c. Specify your own vocabulary with 4 words: [\"atheism\", \"graphics\", \"space\", \"religion\"]. Confirm the training vectors are appropriately shaped. Now what's the average number of non-zero features per example?\n",
    "\n",
    "d. Instead of extracting unigram word features, use \"analyzer\" and \"ngram_range\" to extract bigram and trigram character features. What size vocabulary does this yield?\n",
    "\n",
    "e. Use the \"min_df\" argument to prune words that appear in fewer than 10 documents. What size vocabulary does this yield?\n",
    "\n",
    "f. Using the standard CountVectorizer, what fraction of the words in the dev data are missing from the vocabulary? Hint: build a vocabulary for both train and dev and look at the size of the difference.\n",
    "\n",
    "[6 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumptions:**\n",
    "- I am assuming that we do not carry over the changes from one part to the next. For example, part (e) would not include the ngram character features we implemented in part (d).\n",
    "- I am assuming that in part (d) we are only including the bigram and trigram features and excluding the unigram features. Therefore, I created cases for ngram_range = (2,2), (3,3) and (2,3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part (a):\n",
      "The size of the vocabulary is 26879 unique words\n",
      "The average number of non-zero features per example is 96.71\n",
      "The fraction of the entries in the matrix that are non-zero is 0.003598\n",
      "part (b):\n",
      "The 0th feature string is \"00\" and the last feature string is \"zyxel\"\n",
      "part (c):\n",
      "The training vectors have the shape of: (2034, 4)\n",
      "The average number of non-zero features per example is now 0.27\n",
      "part (d):\n",
      "The size of the vocabulary consisting of only the bigram character features is 3291 unique features\n",
      "The size of the vocabulary consisting of only the trigram character features is 32187 unique features\n",
      "The size of the vocabulary consisting of both the bigram and trigram character features is 35478 unique features\n",
      "part (e):\n",
      "The size of the vocabulary after pruning uncommon words is 3064 unique words\n",
      "part (f):\n",
      "The fraction of words in the dev data that are missing from the train data vocabulary is 0.247876\n"
     ]
    }
   ],
   "source": [
    "# Note to grader: I am assuming that we do not carry over the changes from one part to the next\n",
    "# For example, part (e) would not include the ngram character features we implemented in part (d)\n",
    "\n",
    "def P2():\n",
    "### STUDENT START ###\n",
    "    Vectorizer = CountVectorizer()\n",
    "    fitted = Vectorizer.fit_transform(train_data)\n",
    "    # Each row of fitted is a message and each column is a unique word.\n",
    "    # Numbers in the matrix are counts of each word per message.\n",
    "    \n",
    "    print(\"part (a):\")\n",
    "    # What is the size of the vocabulary?\n",
    "    a1 = len(Vectorizer.get_feature_names())\n",
    "    print(\"The size of the vocabulary is {} unique words\".format(a1))\n",
    "    # What is the average number of non-zero features per example?\n",
    "    a2 = np.mean(fitted.getnnz(1))\n",
    "    print(\"The average number of non-zero features per example is {:.2f}\".format(a2))\n",
    "    # What fraction of the entries in the matrix are non-zero?\n",
    "    a3 = fitted.nnz/(fitted.shape[0]*fitted.shape[1])\n",
    "    print(\"The fraction of the entries in the matrix that are non-zero is {:6f}\".format(a3))\n",
    "    \n",
    "    print(\"part (b):\")\n",
    "    # What are the 0th and last feature strings (in alphabetical order)?\n",
    "    b1 = [Vectorizer.get_feature_names()[0], Vectorizer.get_feature_names()[a1-1]]\n",
    "    print(\"The 0th feature string is \\\"{:s}\\\" and the last feature string is \\\"{:s}\\\"\".format(b1[0], b1[1]))\n",
    "    \n",
    "    print(\"part (c):\")\n",
    "    # Specify your own vocabulary with 4 words: [\"atheism\", \"graphics\", \"space\", \"religion\"]\n",
    "    vocab = [\"atheism\", \"graphics\", \"space\", \"religion\"]\n",
    "    Vectorizer = CountVectorizer(vocabulary = vocab)\n",
    "    fitted = Vectorizer.fit_transform(train_data)\n",
    "    # Confirm the training vectors are appropriately shaped\n",
    "    print(\"The training vectors have the shape of: {}\".format(fitted.shape))\n",
    "    # What's the average number of non-zero features per example?\n",
    "    c1 = np.mean(fitted.getnnz(1))\n",
    "    print(\"The average number of non-zero features per example is now {:.2f}\".format(c1))\n",
    "    \n",
    "    print(\"part (d):\")\n",
    "    # Use \"analyzer\" and \"ngram_range\" to extract bigram and trigram character features\n",
    "    Vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(2,2))\n",
    "    fitted = Vectorizer.fit_transform(train_data)\n",
    "    # What size vocabulary does this yield?\n",
    "    d1 = len(Vectorizer.get_feature_names())\n",
    "    print(\"The size of the vocabulary consisting of only the bigram \"\n",
    "          \"character features is {} unique features\".format(d1))\n",
    "    \n",
    "    Vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(3,3))\n",
    "    fitted = Vectorizer.fit_transform(train_data)\n",
    "    # What size vocabulary does this yield?\n",
    "    d1 = len(Vectorizer.get_feature_names())\n",
    "    print(\"The size of the vocabulary consisting of only the trigram \"\n",
    "          \"character features is {} unique features\".format(d1))\n",
    "    \n",
    "    Vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(2,3))\n",
    "    fitted = Vectorizer.fit_transform(train_data)\n",
    "    # What size vocabulary does this yield?\n",
    "    d1 = len(Vectorizer.get_feature_names())\n",
    "    print(\"The size of the vocabulary consisting of both the bigram \"\n",
    "          \"and trigram character features is {} unique features\".format(d1))\n",
    "    \n",
    "    print(\"part (e):\")\n",
    "    # Use the \"min_df\" argument to prune words that appear in fewer than 10 documents\n",
    "    Vectorizer = CountVectorizer(min_df = 10)\n",
    "    fitted = Vectorizer.fit_transform(train_data)\n",
    "    # What size vocabulary does this yield?\n",
    "    e1 = len(Vectorizer.get_feature_names())\n",
    "    print(\"The size of the vocabulary after pruning uncommon words is {} unique words\".format(e1))\n",
    "    \n",
    "    print(\"part (f):\")\n",
    "    # Build the standard CountVectorizer for both train and dev data\n",
    "    Vectorizer_T = CountVectorizer()\n",
    "    Vectorizer_D = CountVectorizer()\n",
    "    fitted_T = Vectorizer_T.fit_transform(train_data)\n",
    "    fitted_D = Vectorizer_D.fit_transform(dev_data)\n",
    "    # What fraction of the words in the dev data are missing from the vocabulary?\n",
    "    TrainWords = Vectorizer_T.get_feature_names()\n",
    "    DevWords = Vectorizer_D.get_feature_names()\n",
    "    count = 0\n",
    "    for word in DevWords:\n",
    "        if word in TrainWords:\n",
    "            pass\n",
    "        else:\n",
    "            count += 1\n",
    "    print(\"The fraction of words in the dev data that are missing from \"\n",
    "          \"the train data vocabulary is {:4f}\".format(count/len(DevWords)))\n",
    "    \n",
    "### STUDENT END ###\n",
    "P2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Use the default CountVectorizer options and report the f1 score (use metrics.f1_score) for a k nearest neighbors classifier; find the optimal value for k. Also fit a Multinomial Naive Bayes model and find the optimal value for alpha. Finally, fit a logistic regression model and find the optimal value for the regularization strength C using l2 regularization. A few questions:\n",
    "\n",
    "a. Why doesn't nearest neighbors work well for this problem?\n",
    "\n",
    "b. Any ideas why logistic regression doesn't work as well as Naive Bayes?\n",
    "\n",
    "c. Logistic regression estimates a weight vector for each class, which you can access with the coef\\_ attribute. Output the sum of the squared weight values for each class for each setting of the C parameter. Briefly explain the relationship between the sum and the value of C.\n",
    "\n",
    "[4 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumptions:**\n",
    "- I used micro averages when calculating the f1score because there are quite a bit fewer data labeled as religion compared to space.\n",
    "- I wasn't sure if I should use GridSearchCV or iteration to find the optimal k, alpha, and C values for each of the models. On one hand, GridSearchCV does not give the true highest f1score when testing the dev data while interation does. On the other hand, GridSearchCV does multiple cross validations on the training data while iteration does not. In the case of iteration, the k, alpha, and C values might be overfitted to the dev data and less generalized compared to the GridSearchCV. I wrestled with which to use and decided to provide both.\n",
    "- To figure out the optimal k value for the k-NN model, I decided to try a range of integers between 1 to 200. If i only tried a range of integers between 1 and 100, I would get an optimal k of 96."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam Yang: First I wanted to take a look at the distribution of each label under train and dev data to determine if I should use micro or macro averages for f1 score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "# This segment of code will is used to help me figure out if I should use micro or macro averages for f1 score\n",
    "\n",
    "len_dev = len(dev_labels)\n",
    "len_train = len(train_labels)\n",
    "dev_dist = [len(dev_labels[dev_labels == 0])/len_dev, len(dev_labels[dev_labels == 1])/len_dev,\n",
    "           len(dev_labels[dev_labels == 2])/len_dev, len(dev_labels[dev_labels == 3])/len_dev]\n",
    "train_dist = [len(train_labels[train_labels == 0])/len_train, len(train_labels[train_labels == 1])/len_train,\n",
    "           len(train_labels[train_labels == 2])/len_train, len(train_labels[train_labels == 3])/len_train]\n",
    "indices = range(4)\n",
    "width = np.min(np.diff(indices))/3.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(indices-width/2., dev_dist, width = width)\n",
    "ax.bar(indices+width/2., train_dist, width = width)\n",
    "ax.axes.set_xticklabels([\"\",\"\",\"atheism\",\"\",\"comp.graphics\",\"\",\"space\",\"\",\"religion\"])\n",
    "ax.legend([\"dev\", \"train\"])\n",
    "plt.title(\"Percentage of data under each label\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.show()\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam Yang: As shown above, there are fewer labels categorized under religion for both dev and train data so I decided to use micro averaging in the f1 score.**\n",
    "\n",
    "**In the code below, I wrote 2 methods to find the optimal k value and the highest f1score. One method was to use GridSearchCV and the second method is to iteratively calculate the f1score for each of the k values. I decided to use the iterative approach because it actually utilzes the dev data to figure out the optimal k value while the GridSearchCV method breaks up the training data into pieces to find the optimal k value. I was hoping that results will end up being the same but unfortunately that was not the case.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFor kNN:\u001b[0m\n",
      "\u001b[91mUsing GridSearchCV\u001b[0m\n",
      "The optimal k value obtained from GridSearchCV is 151\n",
      "Using GridSearchCV, this results in an f1score of 0.4503\n",
      "The micro f1score with this k value on the dev data is 0.4423\n",
      "\u001b[91mUsing Iteration\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k value between 1 and 200 obtained through iteration is 112\n",
      "This results in the best f1score of 0.4867\n"
     ]
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "### k Nearest Neighbor ###\n",
    "\n",
    "# Build a default CountVectorizer\n",
    "# Fit the CountVectorizer to the training data\n",
    "# Transform the dev data to fit in the CountVectorizer\n",
    "Vectorizer = CountVectorizer()\n",
    "vectorized_T = Vectorizer.fit_transform(train_data)\n",
    "vectorized_D = Vectorizer.transform(dev_data)\n",
    "\n",
    "def kNNf1score(train_data, train_labels, dev_data, dev_labels, k):\n",
    "    \"\"\"Function that inputs train and dev data and k value and \n",
    "    ouputs an f1 score for kNN model\"\"\"\n",
    "    kNN = KNeighborsClassifier(n_neighbors=k)\n",
    "    kNN.fit(train_data, train_labels)\n",
    "    dev_predict = kNN.predict(dev_data)\n",
    "    return(metrics.f1_score(dev_labels, dev_predict, average=\"micro\"))\n",
    "\n",
    "def P3():\n",
    "    print(\"{}For kNN:{}\".format(color.BOLD, color.END))\n",
    "    ### Using GridSearchCV to find the best k value ###\n",
    "    print(\"{}Using GridSearchCV{}\".format(color.RED, color.END))\n",
    "    n_neighbors = {\"n_neighbors\":[i for i in range(1,201)]} \n",
    "    Grid = GridSearchCV(KNeighborsClassifier(), n_neighbors)\n",
    "    Grid.fit(vectorized_T, train_labels)\n",
    "    print(\"The optimal k value obtained from GridSearchCV is {}\".format(Grid.best_params_[\"n_neighbors\"]))\n",
    "    print(\"Using GridSearchCV, this results in an f1score of {:.4f}\".format(Grid.best_score_))\n",
    "    print(\"The micro f1score with this k value on the dev data is {:.4f}\"\n",
    "          .format(kNNf1score(vectorized_T,train_labels,vectorized_D,\n",
    "                             dev_labels,Grid.best_params_[\"n_neighbors\"])))\n",
    "    \n",
    "\n",
    "    ### Using iteration to find the best k value ###\n",
    "    print(\"{}Using Iteration{}\".format(color.RED, color.END))\n",
    "    k = range(1,201)\n",
    "    f1scores = []\n",
    "    best_k = 0\n",
    "    best_f1score = 0\n",
    "    for i in k:\n",
    "        # Calculate the f1score using dev data for each k value\n",
    "        f1score = kNNf1score(vectorized_T,train_labels,vectorized_D,dev_labels,i)\n",
    "        # Add f1score to list for plotting\n",
    "        f1scores.append(f1score)\n",
    "        if f1score > best_f1score:\n",
    "            # Figure out what the best k value and f1score are.\n",
    "            best_k = i\n",
    "            best_f1score = f1score\n",
    "    plt.plot(k,f1scores)\n",
    "    plt.annotate('%s)' %0.49, xy=(112,0.49), xytext=(30,0), textcoords='offset points')\n",
    "    plt.annotate('(%s,' %112, xy=(112,0.49))\n",
    "    plt.title(\"Finding the Optimal k Value of kNN Model\")\n",
    "    plt.xlabel(\"k value\")\n",
    "    plt.ylabel(\"f1 score\")\n",
    "    plt.show()\n",
    "    print(\"The best k value between 1 and 200 obtained through iteration is {}\".format(best_k))\n",
    "    print(\"This results in the best f1score of {:.4f}\".format(best_f1score))\n",
    "\n",
    "### STUDENT END ###\n",
    "P3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFor Multinomial Naive Bayes:\u001b[0m\n",
      "\u001b[91mUsing GridSearchCV\u001b[0m\n",
      "The best alpha value obtained using GridSearchCV is 0.02\n",
      "Using GridSearchCV, this results in an f1score of 0.8289\n",
      "The micro f1score with this alpha value on the dev data is 0.7870\n",
      "\u001b[91mUsing Iteration\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha value is 0.27\n",
      "This results in the best f1score of 0.7944\n"
     ]
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "### Multinomial Naive Bayes ###\n",
    "\n",
    "def NBf1score(train_data, train_labels, dev_data, dev_labels, alpha):\n",
    "    \"\"\"Function that inputs train and dev data and alpha value and \n",
    "    ouputs an f1 score for Multinomial Naive Bayes model\"\"\"\n",
    "    NB = MultinomialNB(alpha=alpha)\n",
    "    NB.fit(train_data, train_labels)\n",
    "    dev_predict = NB.predict(dev_data)\n",
    "    return(metrics.f1_score(dev_labels, dev_predict, average=\"micro\"))\n",
    "\n",
    "def P3():\n",
    "    print(\"{}For Multinomial Naive Bayes:{}\".format(color.BOLD, color.END))\n",
    "    ### Using GridSearchCV to find the best alpha value ###\n",
    "    print(\"{}Using GridSearchCV{}\".format(color.RED, color.END))\n",
    "    alphas = {'alpha': [i/100 for i in range(1,100)]} \n",
    "    Grid = GridSearchCV(MultinomialNB(), alphas)\n",
    "    Grid.fit(vectorized_T, train_labels)\n",
    "    print(\"The best alpha value obtained using GridSearchCV is {}\".format(Grid.best_params_[\"alpha\"]))\n",
    "    print(\"Using GridSearchCV, this results in an f1score of {:.4f}\".format(Grid.best_score_))\n",
    "    print(\"The micro f1score with this alpha value on the dev data is {:.4f}\"\n",
    "          .format(NBf1score(vectorized_T,train_labels,\n",
    "                            vectorized_D,dev_labels,Grid.best_params_[\"alpha\"])))\n",
    "\n",
    "    ### Using iteration to find the best alpha value ###\n",
    "    print(\"{}Using Iteration{}\".format(color.RED, color.END))\n",
    "    alphas = [i/100 for i in range(1,100)]\n",
    "    f1scores = []\n",
    "    best_alpha = 0\n",
    "    best_f1score = 0\n",
    "    for i in alphas:\n",
    "        # Calculate the f1score using dev data for each alpha value\n",
    "        f1score = NBf1score(vectorized_T,train_labels,vectorized_D,dev_labels,i)\n",
    "        # Add f1score to list for plotting\n",
    "        f1scores.append(f1score)\n",
    "        if f1score > best_f1score:\n",
    "            # Figure out what the best k value and f1score are.\n",
    "            best_alpha = i\n",
    "            best_f1score = f1score\n",
    "    plt.plot(alphas,f1scores)\n",
    "    plt.title(\"Finding the Optimal alpha Value of Multinomial NB model\")\n",
    "    plt.xlabel(\"alpha value\")\n",
    "    plt.ylabel(\"f1 score\")\n",
    "    plt.annotate('%s)' %0.7944, xy=(0.27,0.7944), xytext=(30,0), textcoords='offset points')\n",
    "    plt.annotate('(%s,' %0.27, xy=(0.27,0.7944))\n",
    "    plt.show()\n",
    "    print(\"The best alpha value is {}\".format(best_alpha))\n",
    "    print(\"This results in the best f1score of {:.4f}\".format(best_f1score))\n",
    "P3()\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFor Logistic Regression:\u001b[0m\n",
      "\u001b[91mUsing GridSearchCV\u001b[0m\n",
      "The best C value obtained using GridSearchCV is 0.2\n",
      "Using GridSearchCV, this results in an f1score of 0.7763\n",
      "The micro f1score with this C value on the dev data is 0.7130\n",
      "\u001b[91mUsing Iteration\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best C value is 0.3\n",
      "This results in the best f1score of 0.7160\n"
     ]
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "### Logistic Regression ###\n",
    "\n",
    "# fit a logistic regression model and find the optimal value for the regularization strength C using l2 regularization.\n",
    "\n",
    "def Logisticf1score(train_data, train_labels, dev_data, dev_labels, C):\n",
    "    \"\"\"Function that inputs train and dev data and C value and \n",
    "    ouputs an f1 score for Logistic Regression model\"\"\"\n",
    "    LR = LogisticRegression(C=C)\n",
    "    LR.fit(train_data, train_labels)\n",
    "    dev_predict = LR.predict(dev_data)\n",
    "    return(metrics.f1_score(dev_labels, dev_predict, average=\"micro\"))\n",
    "\n",
    "def P3():\n",
    "    print(\"{}For Logistic Regression:{}\".format(color.BOLD, color.END))\n",
    "    ### Using GridSearchCV to find the best C value ###\n",
    "    print(\"{}Using GridSearchCV{}\".format(color.RED, color.END))\n",
    "    C = {'C': [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0]} \n",
    "    Grid = GridSearchCV(LogisticRegression(), C)\n",
    "    Grid.fit(vectorized_T, train_labels)\n",
    "    print(\"The best C value obtained using GridSearchCV is {}\".format(Grid.best_params_[\"C\"]))\n",
    "    print(\"Using GridSearchCV, this results in an f1score of {:.4f}\".format(Grid.best_score_))\n",
    "    print(\"The micro f1score with this C value on the dev data is {:.4f}\"\n",
    "          .format(Logisticf1score(vectorized_T,train_labels,\n",
    "                            vectorized_D,dev_labels,Grid.best_params_[\"C\"])))\n",
    "\n",
    "    ### Using iteration to find the best alpha value ###\n",
    "    print(\"{}Using Iteration{}\".format(color.RED, color.END))\n",
    "    C = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0]\n",
    "    f1scores = []\n",
    "    best_C = 0\n",
    "    best_f1score = 0\n",
    "    for i in C:\n",
    "        # Calculate the f1score using dev data for each C value\n",
    "        f1score = Logisticf1score(vectorized_T,train_labels,vectorized_D,dev_labels,i)\n",
    "        # Add f1score to list for plotting\n",
    "        f1scores.append(f1score)\n",
    "        if f1score > best_f1score:\n",
    "            # Figure out what the best k value and f1score are.\n",
    "            best_C = i\n",
    "            best_f1score = f1score\n",
    "    plt.plot(C,f1scores)\n",
    "    plt.title(\"Finding the Optimal C Value of Multinomial NB model\")\n",
    "    plt.xlabel(\"C value\")\n",
    "    plt.ylabel(\"f1 score\")\n",
    "    plt.annotate('%s)' %0.72, xy=(0.3,0.7160), xytext=(30,0), textcoords='offset points')\n",
    "    plt.annotate('(%s,' %0.3, xy=(0.3,0.7160))\n",
    "    plt.show()\n",
    "    print(\"The best C value is {}\".format(best_C))\n",
    "    print(\"This results in the best f1score of {:.4f}\".format(best_f1score))\n",
    "    \n",
    "P3()\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Why doesn't nearest neighbors work well for this problem?*\n",
    "\n",
    "**ANSWER:** In a k nearest neighbors model, the closest neighboring points to the point we are trying to classify are used to determine the point of that classification. The k nearest neighbors model suffers from the curse of dimensionality where if there is a large multidimensional feature space, the training set will give a poor sampling of the feature space and all the points in the feature would be spread very far apart. Subsequently, it will be very hard for the model to figure out how to properly classify a given point in that feature space. In this case, we have 26,879 features which is much too big of a feature space for a k-NN model to perform well. On top of this, our data is very sparse as we have many zeros in our count-vectorized matrix, which would also contribute to the poor performance of the k-NN model.\n",
    "\n",
    "*Any ideas why logistic regression doesn't work as well as Naive Bayes?*\n",
    "\n",
    "**ANSWER:** Logistic regression and Naive Bayes are both linear classifiers that assign weights to each word to help classify a string of words into a certain category. The main difference is how they assign the weights to each word. Naive Bayes estimates the joint probability p(x,y) from the training data and applies Bayes rule to predict p(y|x) which is used to determine how likely a message is of a certain label given the words that it includes. Logistic regression on the other hand, estimates p(y|x) directly from the training data by minimizing the error of the fit. On top of this, Naive Bayes has the assumption that each of the features (words) are conditionally independent. However, most words are not truly conditionally independent so Naive Bayes will have higher bias than logistic regression. But because Naive Bayes is assuming conditional independence and is essentially using multiple univariate estimators, it would have smaller variance than than logistic regression which is a multivariate estimator. Because of the smaller variance (and bias possibly working in our favor), I believe that Naive Bayes would work better with the sample size we have. We only have 2034 training instances, which means there might not be enough data for a logistic regression to estimate p(y|x) directly with accuracy without overfitting. If the size of the training data was increased, I would expect to see the logistic regression overtake Naive Bayes.\n",
    "\n",
    "**Actual Answer:** Logistic regression doesn't work as well beacuse the number of training examples is small in comparison with the number of features (2034 training examples vs. 26879 features). This is related to the probabilities estimated by each model; logistic regression estimates the conditional probabilities P(y|x) directly while naive bayes estimates the joint probability P(y,x). The few training examples and high number of features make it relatively easier to estimate the latter than the former.\n",
    "\n",
    "*Logistic regression estimates a weight vector for each class, which you can access with the coef_ attribute. Output the sum of the squared weight values for each class for each setting of the C parameter. Briefly explain the relationship between the sum and the value of C.*\n",
    "\n",
    "**ANSWER:** The sum of squared weight values are shown below. It looks like when the C value increases, the sum of squared roots also increases. This makes sense because the smaller the C value, the stronger the regularization strength. Regularization penalizes the magnitude of your parameters when there are a lot of them in order to reduce overfitting when you have many parameters. Therefore, it makes sense that when we decrease the C value, we are increasing the regularization strength, which causes the magnitude of all of the coefficients to be decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 0.01\n",
      "Sum of squared weight values: [2.54 2.94 2.86 2.25]\n",
      "For C = 0.1\n",
      "Sum of squared weight values: [27.13 24.66 27.46 23.02]\n",
      "For C = 0.2\n",
      "Sum of squared weight values: [49.74 42.74 49.33 42.67]\n",
      "For C = 0.3\n",
      "Sum of squared weight values: [69.29 57.88 67.9  59.75]\n",
      "For C = 0.4\n",
      "Sum of squared weight values: [86.74 71.17 84.25 75.06]\n",
      "For C = 0.5\n",
      "Sum of squared weight values: [102.59  83.12  99.03  88.99]\n",
      "For C = 0.6\n",
      "Sum of squared weight values: [117.24  94.04 112.52 101.86]\n",
      "For C = 0.7\n",
      "Sum of squared weight values: [130.89 104.17 124.95 113.9 ]\n",
      "For C = 0.8\n",
      "Sum of squared weight values: [143.56 113.62 136.68 125.06]\n",
      "For C = 0.9\n",
      "Sum of squared weight values: [155.67 122.51 147.62 135.57]\n",
      "For C = 1.0\n",
      "Sum of squared weight values: [167.   130.92 158.02 145.72]\n",
      "For C = 2.0\n",
      "Sum of squared weight values: [257.67 197.98 239.94 226.67]\n"
     ]
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "### Answer to part C ###\n",
    "def Logisticf1score(train_data, train_labels, C):\n",
    "    \"\"\"Function that inputs train and C value and \n",
    "    ouputs the coefficients for Logistic Regression model\"\"\"\n",
    "    LR = LogisticRegression(C=C)\n",
    "    LR.fit(train_data, train_labels)\n",
    "    return(LR.coef_)\n",
    "\n",
    "def P3():\n",
    "    C = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0]\n",
    "    for i in C:\n",
    "        print(\"For C = {}\".format(i))\n",
    "        # Calculate the coef_attribute for each C value\n",
    "        coefs = Logisticf1score(vectorized_T,train_labels,i)\n",
    "        sumsquared = np.sum(np.square(coefs), axis=1)\n",
    "        print(\"Sum of squared weight values: {}\".format(np.round(sumsquared, 2)))        \n",
    "P3()\n",
    "\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Train a logistic regression model. Find the 5 features with the largest weights for each label -- 20 features in total. Create a table with 20 rows and 4 columns that shows the weight for each of these features for each of the labels. Create the table again with bigram features. Any surprising features in this table?\n",
    "\n",
    "[5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Assumptions:***\n",
    "- I am assuming that for the bigram CountVectorizer, we only include the bigram words. Therefore, ngram_range = (2,2).\n",
    "- I set a C value for the logistic regression as 0.2 because earlier we found this to provide a more accurate model.\n",
    "- I am assuming we are looking for the largest positive weights instead of the largest absolute weights because the positive weights indicate which words are mostly likely included for each label.\n",
    "- I am assuming for the bigram vectorizer, we use the \"word\" analyzer instead of \"char\" because it makes much more sense to use combinations of words than combination of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mFor the Unigram Example:\u001b[0m\n",
      "\u001b[1mUnder the alt.atheism label:\u001b[0m\n",
      "The word \"bobby\", with index 4784, and a coefficient of 0.6193\n",
      "The word \"atheism\", with index 3866, and a coefficient of 0.6158\n",
      "The word \"religion\", with index 20430, and a coefficient of 0.6153\n",
      "The word \"atheists\", with index 3870, and a coefficient of 0.6065\n",
      "The word \"islam\", with index 13668, and a coefficient of 0.5281\n",
      "\u001b[1mUnder the comp.graphics label:\u001b[0m\n",
      "The word \"graphics\", with index 11552, and a coefficient of 1.2552\n",
      "The word \"image\", with index 12769, and a coefficient of 0.8328\n",
      "The word \"file\", with index 10376, and a coefficient of 0.8082\n",
      "The word \"3d\", with index 1145, and a coefficient of 0.7104\n",
      "The word \"computer\", with index 6555, and a coefficient of 0.6793\n",
      "\u001b[1mUnder the sci.space label:\u001b[0m\n",
      "The word \"space\", with index 22567, and a coefficient of 1.5060\n",
      "The word \"orbit\", with index 17597, and a coefficient of 0.7623\n",
      "The word \"nasa\", with index 16697, and a coefficient of 0.6645\n",
      "The word \"launch\", with index 14540, and a coefficient of 0.6011\n",
      "The word \"spacecraft\", with index 22570, and a coefficient of 0.5244\n",
      "\u001b[1mUnder the talk.religion.misc label:\u001b[0m\n",
      "The word \"christian\", with index 5901, and a coefficient of 0.6963\n",
      "The word \"christians\", with index 5904, and a coefficient of 0.6680\n",
      "The word \"blood\", with index 4743, and a coefficient of 0.5970\n",
      "The word \"fbi\", with index 10234, and a coefficient of 0.5580\n",
      "The word \"order\", with index 17609, and a coefficient of 0.5540\n",
      "\n",
      "\u001b[1mTable for Unigram Logistic Regression\u001b[0m\n",
      "      Feature       |    alt.atheism     |   comp.graphics    |     sci.space      | talk.religion.misc |\n",
      "bobby               |              0.6193|              -0.151|             -0.2164|             -0.2931|\n",
      "atheism             |              0.6158|             -0.2674|             -0.2664|             -0.3125|\n",
      "religion            |              0.6153|             -0.3814|             -0.4999|             -0.0197|\n",
      "atheists            |              0.6065|             -0.0869|             -0.2026|             -0.4206|\n",
      "islam               |              0.5281|             -0.0942|              -0.213|             -0.2149|\n",
      "graphics            |             -0.5031|              1.2552|             -0.8291|             -0.4712|\n",
      "image               |             -0.3421|              0.8328|             -0.4877|             -0.2802|\n",
      "file                |             -0.2139|              0.8082|             -0.5287|             -0.3726|\n",
      "3d                  |              -0.232|              0.7104|             -0.4143|             -0.2378|\n",
      "computer            |             -0.0046|              0.6793|              -0.427|             -0.2937|\n",
      "space               |             -0.8191|             -0.8751|               1.506|             -0.7409|\n",
      "orbit               |             -0.2716|             -0.4248|              0.7623|              -0.345|\n",
      "nasa                |             -0.3463|             -0.3226|              0.6645|             -0.3153|\n",
      "launch              |             -0.2744|             -0.3082|              0.6011|             -0.2147|\n",
      "spacecraft          |             -0.2237|             -0.2393|              0.5244|             -0.1961|\n",
      "christian           |             -0.3442|             -0.2483|             -0.2211|              0.6963|\n",
      "christians          |             -0.4426|             -0.2188|             -0.2771|               0.668|\n",
      "blood               |             -0.2965|             -0.0786|             -0.1438|               0.597|\n",
      "fbi                 |             -0.1704|             -0.1521|             -0.2839|               0.558|\n",
      "order               |             -0.4735|              -0.049|             -0.0981|               0.554|\n",
      "\n",
      "\u001b[4m\u001b[1mFor the Bigram Example:\u001b[0m\n",
      "\u001b[1mUnder the alt.atheism label:\u001b[0m\n",
      "The word \"cheers kent\", with index 37174, and a coefficient of 0.4187\n",
      "The word \"claim that\", with index 38326, and a coefficient of 0.4047\n",
      "The word \"in this\", with index 83190, and a coefficient of 0.3622\n",
      "The word \"is not\", with index 88101, and a coefficient of 0.3539\n",
      "The word \"are you\", with index 20596, and a coefficient of 0.3500\n",
      "\u001b[1mUnder the comp.graphics label:\u001b[0m\n",
      "The word \"looking for\", with index 98723, and a coefficient of 0.8482\n",
      "The word \"in advance\", with index 81950, and a coefficient of 0.6534\n",
      "The word \"out there\", with index 123709, and a coefficient of 0.5851\n",
      "The word \"is there\", with index 88596, and a coefficient of 0.5534\n",
      "The word \"comp graphics\", with index 40451, and a coefficient of 0.5367\n",
      "\u001b[1mUnder the sci.space label:\u001b[0m\n",
      "The word \"the moon\", with index 165984, and a coefficient of 0.6768\n",
      "The word \"the space\", with index 167336, and a coefficient of 0.6683\n",
      "The word \"sci space\", with index 145068, and a coefficient of 0.4713\n",
      "The word \"and such\", with index 16732, and a coefficient of 0.4634\n",
      "The word \"it was\", with index 90070, and a coefficient of 0.4119\n",
      "\u001b[1mUnder the talk.religion.misc label:\u001b[0m\n",
      "The word \"cheers kent\", with index 37174, and a coefficient of 0.4245\n",
      "The word \"the fbi\", with index 164806, and a coefficient of 0.4181\n",
      "The word \"with you\", with index 190525, and a coefficient of 0.3407\n",
      "The word \"but he\", with index 32640, and a coefficient of 0.3404\n",
      "The word \"the word\", with index 168057, and a coefficient of 0.3226\n",
      "\n",
      "\u001b[1mTable for Bigram Logistic Regression\u001b[0m\n",
      "      Feature       |    alt.atheism     |   comp.graphics    |     sci.space      | talk.religion.misc |\n",
      "cheers kent         |              0.4187|             -0.4956|             -0.4782|              0.4245|\n",
      "claim that          |              0.4047|             -0.1378|             -0.1904|             -0.0842|\n",
      "in this             |              0.3622|             -0.0099|             -0.3714|             -0.0857|\n",
      "is not              |              0.3539|             -0.1779|              -0.346|               0.034|\n",
      "are you             |                0.35|             -0.1862|             -0.0856|               -0.21|\n",
      "looking for         |             -0.4831|              0.8482|             -0.3735|             -0.4248|\n",
      "in advance          |             -0.3554|              0.6534|             -0.3302|             -0.3151|\n",
      "out there           |             -0.2158|              0.5851|             -0.3579|               -0.21|\n",
      "is there            |             -0.2409|              0.5534|             -0.3517|             -0.1713|\n",
      "comp graphics       |             -0.2034|              0.5367|             -0.2667|             -0.1814|\n",
      "the moon            |             -0.2817|             -0.3858|              0.6768|             -0.1812|\n",
      "the space           |             -0.2119|              -0.387|              0.6683|             -0.2132|\n",
      "sci space           |             -0.1903|             -0.2552|              0.4713|             -0.1615|\n",
      "and such            |             -0.1569|             -0.2587|              0.4634|             -0.1698|\n",
      "it was              |             -0.1413|             -0.2434|              0.4119|             -0.2245|\n",
      "cheers kent         |              0.4187|             -0.4956|             -0.4782|              0.4245|\n",
      "the fbi             |             -0.0941|              -0.152|             -0.2167|              0.4181|\n",
      "with you            |             -0.1596|              0.0437|             -0.2513|              0.3407|\n",
      "but he              |             -0.1209|             -0.1502|             -0.0923|              0.3404|\n",
      "the word            |              0.0461|             -0.1856|             -0.2047|              0.3226|\n"
     ]
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "# Build a default CountVectorizer\n",
    "# Fit the CountVectorizer to the training data\n",
    "# Unigram\n",
    "Vectorizer = CountVectorizer()\n",
    "vectorized_T = Vectorizer.fit_transform(train_data)\n",
    "# Bigram\n",
    "Vectorizer2 = CountVectorizer(ngram_range=(2,2))\n",
    "vectorized_T2 = Vectorizer2.fit_transform(train_data)\n",
    "\n",
    "def P4():\n",
    "    # Train a unigram logistic regression model\n",
    "    # I used C = 0.2 because we found that to be a possible ideal C value for this data\n",
    "    LR = LogisticRegression(C = 0.2)\n",
    "    LR.fit(vectorized_T, train_labels)\n",
    "    \n",
    "    # Find the 5 features with the largest weights for each label\n",
    "    # I am assuming we are looking for the largest positive weights because \n",
    "    # they indicate which words are most likely part of each label.\n",
    "    indices = np.argsort(LR.coef_, axis = 1)[:,::-1][:,0:5]\n",
    "    coefs = np.sort(LR.coef_, axis = 1)[:,::-1][:,0:5]\n",
    "    \n",
    "    # Print out the 5 parameters for each label\n",
    "    print(\"{}{}For the Unigram Example:{}\".format(color.UNDERLINE,color.BOLD,color.END))\n",
    "    for i in range(4):\n",
    "        print(\"{}Under the {} label:{}\".format(color.BOLD,newsgroups_train.target_names[i],color.END))\n",
    "        for j in range(5):\n",
    "            print(\"The word \\\"{}\\\", with index {}, and a coefficient of {:.4f}\"\n",
    "                  .format(Vectorizer.get_feature_names()[indices[i,j]],indices[i,j], coefs[i,j]))\n",
    "            \n",
    "    # Create a table that shows the weight for each of these features for each of the labels\n",
    "    print(\"\\n{}Table for Unigram Logistic Regression{}\".format(color.BOLD,color.END))\n",
    "    print(\"{:^20}|{:^20}|{:^20}|{:^20}|{:^20}|\".format(\"Feature\",newsgroups_train.target_names[0],\n",
    "                                             newsgroups_train.target_names[1],\n",
    "                                             newsgroups_train.target_names[2],\n",
    "                                             newsgroups_train.target_names[3]))\n",
    "    for index in indices.flatten():\n",
    "        print(\"{:20}|{:20}|{:20}|{:20}|{:20}|\".format(Vectorizer.get_feature_names()[index],\n",
    "                                                        np.round(LR.coef_[0,index],4),\n",
    "                                                        np.round(LR.coef_[1,index],4),\n",
    "                                                        np.round(LR.coef_[2,index],4),\n",
    "                                                        np.round(LR.coef_[3,index],4)))\n",
    "    \n",
    "    # Train a bigram logistic regression model\n",
    "    LR2 = LogisticRegression(C = 0.2)\n",
    "    LR2.fit(vectorized_T2, train_labels)\n",
    "    \n",
    "    # Find the 5 features with the largest weights for each label\n",
    "    indices2 = np.argsort(LR2.coef_, axis = 1)[:,::-1][:,0:5]\n",
    "    coefs2 = np.sort(LR2.coef_, axis = 1)[:,::-1][:,0:5]\n",
    "    \n",
    "    # Print out the 5 parameters for each label\n",
    "    print(\"\\n{}{}For the Bigram Example:{}\".format(color.UNDERLINE,color.BOLD,color.END))\n",
    "    for i in range(4):\n",
    "        print(\"{}Under the {} label:{}\".format(color.BOLD,newsgroups_train.target_names[i],color.END))\n",
    "        for j in range(5):\n",
    "            print(\"The word \\\"{}\\\", with index {}, and a coefficient of {:.4f}\"\n",
    "                  .format(Vectorizer2.get_feature_names()[indices2[i,j]],indices2[i,j], coefs2[i,j]))\n",
    "    \n",
    "    # Create a table that shows the weight for each of these features for each of the labels\n",
    "    print(\"\\n{}Table for Bigram Logistic Regression{}\".format(color.BOLD,color.END))\n",
    "    print(\"{:^20}|{:^20}|{:^20}|{:^20}|{:^20}|\".format(\"Feature\",newsgroups_train.target_names[0],\n",
    "                                             newsgroups_train.target_names[1],\n",
    "                                             newsgroups_train.target_names[2],\n",
    "                                             newsgroups_train.target_names[3]))\n",
    "    for index in indices2.flatten():\n",
    "        print(\"{:20}|{:20}|{:20}|{:20}|{:20}|\".format(Vectorizer2.get_feature_names()[index],\n",
    "                                                        np.round(LR2.coef_[0,index],4),\n",
    "                                                        np.round(LR2.coef_[1,index],4),\n",
    "                                                        np.round(LR2.coef_[2,index],4),\n",
    "                                                        np.round(LR2.coef_[3,index],4)))\n",
    "P4()\n",
    "\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Any surprising features in this table (The bigram table)?*\n",
    "\n",
    "**ANSWER:** I think I am surprised that features like \"in this\", \"is not\", \"are you\", \"it was\", etc made the list because they are so general and can apply to any type of sentence. I think the unigram logistic regression is a better model overall and even if we wanted to include bigram features in our model, we should keep the unigram features in the model. One interesting bigram feature is \"cheers kent\" which appears to be the highest weighted feature for both atheism and religion. I think maybe this guy Kent writes a lot about atheism and religion and ends his writings with \"cheers kent\", which is why it is such a strong feature for those two categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Try to improve the logistic regression classifier by passing a custom preprocessor to CountVectorizer. The preprocessing function runs on the raw text, before it is split into words by the tokenizer. Your preprocessor should try to normalize the input in various ways to improve generalization. For example, try lowercasing everything, replacing sequences of numbers with a single token, removing various other non-letter characters, and shortening long words. If you're not already familiar with regular expressions for manipulating strings, see https://docs.python.org/2/library/re.html, and re.sub() in particular. With your new preprocessor, how much did you reduce the size of the dictionary?\n",
    "\n",
    "For reference, I was able to improve dev F1 by 2 points.\n",
    "\n",
    "[4 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Assumptions:***\n",
    "- Assuming that we are expected to use the default logistic regression classifier where C = 1 and L2 regularization.\n",
    "- I used the \"weighted\" average f1score because the \"micro\" average f1score that I have been using is the same as the accuracy score.\n",
    "- I created a \"best_preprocessor\" which I played around with for a long time to try and get the highest accuracy. It is very much overfitted to the specific training and dev data because I only included things that helped increase the accuracy. This was just for fun to see how high I can get the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFor empty_preprocessor:\u001b[0m\n",
      "The size of the dictionary is 26879\n",
      "The accuracy is 0.70118\n",
      "The \"weighted\" average f1score is 0.69609\n",
      "\u001b[1mFor better_preprocessor:\u001b[0m\n",
      "The size of the dictionary is 22454\n",
      "The accuracy is 0.72633\n",
      "The \"weighted\" average f1score is 0.72057\n",
      "\u001b[1mFor best_preprocessor:\u001b[0m\n",
      "The size of the dictionary is 24750\n",
      "The accuracy is 0.73669\n",
      "The \"weighted\" average f1score is 0.73285\n"
     ]
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "def empty_preprocessor(s):\n",
    "    return s\n",
    "\n",
    "def better_preprocessor(s):\n",
    "    # Remove symbols\n",
    "    s = re.sub(r\"[_@$&%#]\",\"\",s)\n",
    "    \n",
    "    # Remove certain suffixes\n",
    "    s = re.sub(r\"y\\b|s\\b|ed\\b|ly\\b|ing\\b\",\"\",s)\n",
    "    \n",
    "    # Remove the stop words\n",
    "    s = \" \".join([word for word in s.split() if word not in ENGLISH_STOP_WORDS])\n",
    "    \n",
    "    return s\n",
    "\n",
    "def best_preprocessor(s):\n",
    "    # This preprocessor is very much overfitting to our specific train and dev data.\n",
    "    # The only purpose of this is to see how high I can get the accuracy.\n",
    "    \n",
    "    # Remove \"_\" and \"@\" symbols\n",
    "    s = re.sub(r\"[_@]\",\"\",s)\n",
    "    \n",
    "    # Remove certain suffixes\n",
    "    s = re.sub(r\"y\\b|s\\b|ed\\b|ly\\b\",\"\",s)\n",
    "    \n",
    "    # Remove certain English Stop Words\n",
    "    s = re.sub(r\" your | had | do | between | before \",\"\",s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "def P5():\n",
    "    \n",
    "    for preprocessor in [empty_preprocessor, better_preprocessor, best_preprocessor]:\n",
    "        print(\"{}For {}:{}\".format(color.BOLD,preprocessor.__name__,color.END))\n",
    "        # First preprocess each message in the train_data and dev data\n",
    "        preproc_train = [preprocessor(message) for message in train_data]\n",
    "        preproc_dev = [preprocessor(message) for message in dev_data]\n",
    "\n",
    "        # Create a CountVectorizer for the preprocessed training data and dev data\n",
    "        Vectorizer = CountVectorizer()\n",
    "        vectorized_T = Vectorizer.fit_transform(preproc_train)\n",
    "        vectorized_D = Vectorizer.transform(preproc_dev)\n",
    "        print(\"The size of the dictionary is {}\".format(len(Vectorizer.get_feature_names())))\n",
    "        #print(Vectorizer.get_feature_names())\n",
    "        \n",
    "        # Build a logistic regression classifier\n",
    "        LR = LogisticRegression()\n",
    "        LR.fit(vectorized_T, train_labels)\n",
    "        \n",
    "        # Print out the accuracy and f1score\n",
    "        print(\"The accuracy is {:.5f}\".format(LR.score(vectorized_D,dev_labels)))\n",
    "        dev_predict = LR.predict(vectorized_D)\n",
    "        print(\"The \\\"weighted\\\" average f1score is {:.5f}\"\n",
    "              .format(metrics.f1_score(dev_labels, dev_predict, average=\"weighted\")))\n",
    "P5()\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your new preprocessor, how much did you reduce the size of the dictionary?\n",
    "\n",
    "**ANSWER:** I reduced the size of the dictionary by 4425 with my \"better_preprocessor\". The accuracy was increased by around 2.5 points for the \"better_preprocessor\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) The idea of regularization is to avoid learning very large weights (which are likely to fit the training data, but not generalize well) by adding a penalty to the total size of the learned weights. That is, logistic regression seeks the set of weights that minimizes errors in the training data AND has a small size. The default regularization, L2, computes this size as the sum of the squared weights (see P3, above). L1 regularization computes this size as the sum of the absolute values of the weights. The result is that whereas L2 regularization makes all the weights relatively small, L1 regularization drives lots of the weights to 0, effectively removing unimportant features.\n",
    "\n",
    "Train a logistic regression model using a \"l1\" penalty. Output the number of learned weights that are not equal to zero. How does this compare to the number of non-zero weights you get with \"l2\"? Now, reduce the size of the vocabulary by keeping only those features that have at least one non-zero weight and retrain a model using \"l2\".\n",
    "\n",
    "Make a plot showing accuracy of the re-trained model vs. the vocabulary size you get when pruning unused features by adjusting the C parameter.\n",
    "\n",
    "Note: The gradient descent code that trains the logistic regression model sometimes has trouble converging with extreme settings of the C parameter. Relax the convergence criteria by setting tol=.01 (the default is .0001).\n",
    "\n",
    "[4 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of learned weights that are not equal to zero using L1 Regularization is 1609\n",
      "The accuracy is 0.6879\n",
      "The number of learned weights that are not equal to zero using L2 Regularization is 107516\n",
      "The accuracy is 0.7012\n",
      "The number of learned weights that are not equal to zero using L2 Regularization on the reduced vocabulary is 3832\n",
      "The accuracy is 0.6805\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "def P6():\n",
    "    # Keep this random seed here to make comparison easier.\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    Vectorizer = CountVectorizer()\n",
    "    vectorized_T = Vectorizer.fit_transform(train_data)\n",
    "    vectorized_D = Vectorizer.transform(dev_data)\n",
    "    # Build a Logistic Regression Model using L1 regularization\n",
    "    LR = LogisticRegression(penalty=\"l1\")\n",
    "    LR.fit(vectorized_T, train_labels)\n",
    "    # Output the number of learned weights that are not equal to zero\n",
    "    num_coefs = np.count_nonzero(LR.coef_)\n",
    "    print(\"The number of learned weights that are not equal to \"\n",
    "          \"zero using L1 Regularization is {}\".format(num_coefs))\n",
    "    accuracy = LR.score(vectorized_D, dev_labels)\n",
    "    print(\"The accuracy is {:.4f}\".format(accuracy))\n",
    "    \n",
    "    # Build a Logistic Regression Model using L2 regularization\n",
    "    LR2 = LogisticRegression(penalty=\"l2\")\n",
    "    LR2.fit(vectorized_T, train_labels)\n",
    "    # Output the number of learned weights that are not equal to zero\n",
    "    num_coefs2 = np.count_nonzero(LR2.coef_)\n",
    "    print(\"The number of learned weights that are not equal to \"\n",
    "          \"zero using L2 Regularization is {}\".format(num_coefs2))\n",
    "    accuracy2 = LR2.score(vectorized_D, dev_labels)\n",
    "    print(\"The accuracy is {:.4f}\".format(accuracy2))\n",
    "\n",
    "    # Now, reduce the size of the vocabulary by keeping only those features \n",
    "    # that have at least one non-zero weight and retrain a modeling using \"l2\".\n",
    "    # These are the unique indices of all the non-zero weight words.\n",
    "    # I looked for unique indices because each index can appear up to 4 times.\n",
    "    indices = np.unique(np.nonzero(LR.coef_)[1])\n",
    "    wordlist = np.array(Vectorizer.get_feature_names())[indices]\n",
    "    Vectorizer = CountVectorizer(vocabulary=wordlist)\n",
    "    vectorized_T = Vectorizer.fit_transform(train_data)\n",
    "    vectorized_D = Vectorizer.transform(dev_data)\n",
    "    LR3 = LogisticRegression(penalty=\"l2\")\n",
    "    LR3.fit(vectorized_T, train_labels)\n",
    "    num_coefs3 = np.count_nonzero(LR3.coef_)\n",
    "    print(\"The number of learned weights that are not equal to \"\n",
    "          \"zero using L2 Regularization on the reduced vocabulary is {}\".format(num_coefs3))\n",
    "    accuracy3 = LR3.score(vectorized_D, dev_labels)\n",
    "    print(\"The accuracy is {:.4f}\".format(accuracy3))\n",
    "    \n",
    "    # Make a plot showing accuracy of the re-trained model vs. the vocabulary size you \n",
    "    # get when pruning unused features by adjusting the C parameter.\n",
    "    C = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0]\n",
    "    vocab_sizes = []\n",
    "    accuracies = []\n",
    "    for c in C:\n",
    "        # Find a smaller vocab size with \"l1\" regularization\n",
    "        Vectorizer = CountVectorizer()\n",
    "        vectorized_T = Vectorizer.fit_transform(train_data)\n",
    "        LR = LogisticRegression(penalty=\"l1\", C = c, tol=0.01)\n",
    "        LR.fit(vectorized_T, train_labels)\n",
    "        # Add vocab size to the list\n",
    "        vocab_sizes.append(np.count_nonzero(LR.coef_))\n",
    "        indices = np.unique(np.nonzero(LR.coef_)[1])\n",
    "        wordlist = np.array(Vectorizer.get_feature_names())[indices]\n",
    "        # Create a new vectorizer and \"l2\" logistic regression with new vocab list\n",
    "        Vectorizer = CountVectorizer(vocabulary=wordlist)\n",
    "        vectorized_T = Vectorizer.fit_transform(train_data)\n",
    "        vectorized_D = Vectorizer.transform(dev_data)\n",
    "        # I am assuming we keep C = 1 for this regression\n",
    "        LR2 = LogisticRegression(penalty=\"l2\", tol=0.01)\n",
    "        LR2.fit(vectorized_T, train_labels)\n",
    "        accuracies.append(LR2.score(vectorized_D, dev_labels))\n",
    "    plt.plot(vocab_sizes, accuracies, \"bo-\")\n",
    "    plt.title(\"Accuracy of L2 Logistic Regression vs. Different Vocabulary Sizes\")\n",
    "    plt.xlabel(\"Vocabulary Size (obtained by pruning unused features by adjusting the C parameter in L1 regressions)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "P6()\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How does the number of non-zero weights you get with \"l1\" compare to the number of non-zero weights you get with \"l2\"?*\n",
    "\n",
    "**ANSWER:** Using L1 regularization, we get 1609 non-zero weights which is 105907 fewer than if we used L2 regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Use the TfidfVectorizer -- how is this different from the CountVectorizer? Train a logistic regression model with C=100.\n",
    "\n",
    "Make predictions on the dev data and show the top 3 documents where the ratio R is largest, where R is:\n",
    "\n",
    "maximum predicted probability / predicted probability of the correct label\n",
    "\n",
    "What kinds of mistakes is the model making? Suggest a way to address one particular issue that you see.\n",
    "\n",
    "[4 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe 1st highest R value is 929.3574\u001b[0m\n",
      "The predicted probabilities are [0.00196657 0.99371933 0.00324484 0.00106925]\n",
      "This means the predicted label for this message is comp.graphics\n",
      "The actual label for this message is talk.religion.misc\n",
      "The message is:\n",
      "\n",
      "I am pleased to announce that a *revised version* of _The Easy-to-Read Book\n",
      "of Mormon_ (former title: _Mormon's Book_) by Lynn Matthews Anderson is now\n",
      "available through anonymous ftp (see information below). In addition to the\n",
      "change in title, the revised ETR BOM has been shortened by several pages\n",
      "(eliminating many extraneous \"that's\" and \"of's\"), and many (minor) errors\n",
      "have been corrected. This release includes a simplified Joseph Smith Story,\n",
      "testimonies of the three and eight witnesses, and a \"Words-to-Know\"\n",
      "glossary.\n",
      "\n",
      "As with the previous announcement, readers are reminded that this is a\n",
      "not-for-profit endeavor. This is a copyrighted work, but people are welcome\n",
      "to make *verbatim* copies for personal use. People can recuperate the\n",
      "actual costs of printing (paper, copy center charges), but may not charge\n",
      "anything for their time in making copies, or in any way realize a profit\n",
      "from the use of this book. See the permissions notice in the book itself\n",
      "for the precise terms.\n",
      "\n",
      "Negotiations are currently underway with a Mormon publisher vis-a-vis the\n",
      "printing and distribution of bound books. (Sorry, I'm out of the wire-bound\n",
      "\"first editions.\") I will make another announcement about the availability\n",
      "of printed copies once everything has been worked out.\n",
      "\n",
      "FTP information: connect via anonymous ftp to carnot.itc.cmu.edu, then \"cd\n",
      "pub\" (you won't see anything at all until you do).\n",
      "\n",
      "\"The Easy-to-Read Book of Mormon\" is currently available in postscript and\n",
      "RTF (rich text format). (ASCII, LaTeX, and other versions can be made\n",
      "available; contact dba@andrew.cmu.edu for details.) You should be able to\n",
      "print the postscript file on any postscript printer (such as an Apple\n",
      "Laserwriter); let dba know if you have any difficulties. (The postscript in\n",
      "the last release had problems on some printers; this time it should work\n",
      "better.) RTF is a standard document interchange format that can be read in\n",
      "by a number of word processors, including Microsoft Word for both the\n",
      "Macintosh and Windows. If you don't have a postscript printer, you may be\n",
      "able to use the RTF file to print out a copy of the book.\n",
      "\n",
      "-r--r--r--  1 dba                   1984742 Apr 27 13:12 etrbom.ps\n",
      "-r--r--r--  1 dba                   1209071 Apr 27 13:13 etrbom.rtf\n",
      "\n",
      "For more information about how this project came about, please refer to my\n",
      "article in the current issue of _Sunstone_, entitled \"Delighting in\n",
      "Plainness: Issues Surrounding a Simple Modern English Book of Mormon.\"\n",
      "\n",
      "Send all inquiries and comments to:\n",
      "\n",
      "    Lynn Matthews Anderson\n",
      "    5806 Hampton Street\n",
      "    Pittsburgh, PA 15206\n",
      "\n",
      "\u001b[1mThe 2nd highest R value is 325.0039\u001b[0m\n",
      "The predicted probabilities are [0.00291175 0.97974442 0.01432926 0.00301456]\n",
      "This means the predicted label for this message is comp.graphics\n",
      "The actual label for this message is talk.religion.misc\n",
      "The message is:\n",
      "\n",
      "Can anyone provide me a ftp site where I can obtain a online version\n",
      "of the Book of Mormon. Please email the internet address if possible.\n",
      "\n",
      "\u001b[1mThe 3rd highest R value is 287.3069\u001b[0m\n",
      "The predicted probabilities are [0.00241987 0.02006467 0.28226889 0.69524657]\n",
      "This means the predicted label for this message is talk.religion.misc\n",
      "The actual label for this message is alt.atheism\n",
      "The message is:\n",
      "\n",
      "\n",
      "The 24 children were, of course, killed by a lone gunman in a second story\n",
      "window, who fired eight bullets in the space of two seconds...\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1mThe highest weighted words for each label:\u001b[0m\n",
      "\u001b[1mUnder the alt.atheism label:\u001b[0m\n",
      "The word \"atheism\", with index 3866, and a coefficient of 9.1990\n",
      "The word \"atheists\", with index 3870, and a coefficient of 8.1651\n",
      "The word \"religion\", with index 20430, and a coefficient of 7.7942\n",
      "The word \"bobby\", with index 4784, and a coefficient of 7.3494\n",
      "The word \"islam\", with index 13668, and a coefficient of 7.0469\n",
      "\u001b[1mUnder the comp.graphics label:\u001b[0m\n",
      "The word \"graphics\", with index 11552, and a coefficient of 14.0647\n",
      "The word \"image\", with index 12769, and a coefficient of 10.1153\n",
      "The word \"computer\", with index 6555, and a coefficient of 8.9138\n",
      "The word \"file\", with index 10376, and a coefficient of 8.8849\n",
      "The word \"3d\", with index 1145, and a coefficient of 8.7113\n",
      "\u001b[1mUnder the sci.space label:\u001b[0m\n",
      "The word \"space\", with index 22567, and a coefficient of 19.1876\n",
      "The word \"orbit\", with index 17597, and a coefficient of 9.2027\n",
      "The word \"nasa\", with index 16697, and a coefficient of 8.3108\n",
      "The word \"launch\", with index 14540, and a coefficient of 7.8536\n",
      "The word \"spacecraft\", with index 22570, and a coefficient of 6.8658\n",
      "\u001b[1mUnder the talk.religion.misc label:\u001b[0m\n",
      "The word \"christian\", with index 5901, and a coefficient of 9.9067\n",
      "The word \"blood\", with index 4743, and a coefficient of 7.7797\n",
      "The word \"christians\", with index 5904, and a coefficient of 7.6580\n",
      "The word \"fbi\", with index 10234, and a coefficient of 7.5582\n",
      "The word \"order\", with index 17609, and a coefficient of 6.3082\n",
      "\n",
      "\u001b[1mThe accuracy of this model is 0.7633136094674556\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "def P7():\n",
    "    # Create a TfidfVectorizer\n",
    "    Vectorizer = TfidfVectorizer()\n",
    "    vectorized_T = Vectorizer.fit_transform(train_data)\n",
    "    vectorized_D = Vectorizer.transform(dev_data)\n",
    "    # Create a Logistic Regression with C = 100\n",
    "    LR = LogisticRegression(C = 100)\n",
    "    LR.fit(vectorized_T, train_labels)\n",
    "    # Find the predict probabilities in for each label for each message \n",
    "    probs = LR.predict_proba(vectorized_D)\n",
    "    # Iterate through these probabilities to find the R ratio\n",
    "    Rratio = []\n",
    "    for i in range(len(probs)):\n",
    "        # Find the maximum predicted probability for this message\n",
    "        maxpredprob = np.max(probs[i])\n",
    "        # Find the correct label for this message\n",
    "        corr_label = dev_labels[i]\n",
    "        # Find the predicted probability associated of the correct label for this message\n",
    "        corrpredprob = probs[i][corr_label]\n",
    "        # Find the R ratio\n",
    "        R = maxpredprob/corrpredprob\n",
    "        Rratio.append(R)\n",
    "    # Find the top 3 R ratios and their indices\n",
    "    TopRs = np.sort(Rratio)[::-1][:3]\n",
    "    TopRsIndex = np.argsort(Rratio)[::-1][:3]\n",
    "    labels = newsgroups_train.target_names\n",
    "    \n",
    "    for i in range(3):\n",
    "        order = [\"1st\",\"2nd\",\"3rd\"]\n",
    "        print(\"{}The {} highest R value is {:.4f}{}\".format(color.BOLD,order[i],TopRs[i],color.END))\n",
    "        predprobs = probs[TopRsIndex[i]]\n",
    "        print(\"The predicted probabilities are {}\".format(predprobs))\n",
    "        print(\"This means the predicted label for this message is {}\".format(labels[np.argmax(predprobs)]))\n",
    "        print(\"The actual label for this message is {}\".format(labels[dev_labels[TopRsIndex[i]]]))\n",
    "        print(\"The message is:\\n\\n{}\\n\".format(dev_data[TopRsIndex[i]]))\n",
    "    \n",
    "    indices = np.argsort(LR.coef_, axis = 1)[:,::-1][:,0:5]\n",
    "    coefs = np.sort(LR.coef_, axis = 1)[:,::-1][:,0:5]\n",
    "    \n",
    "    # Print out the 5 parameters for each label\n",
    "    print(\"{}{}The highest weighted words for each label:{}\".format(color.UNDERLINE,color.BOLD,color.END))\n",
    "    for i in range(4):\n",
    "        print(\"{}Under the {} label:{}\".format(color.BOLD,labels[i],color.END))\n",
    "        for j in range(5):\n",
    "            print(\"The word \\\"{}\\\", with index {}, and a coefficient of {:.4f}\"\n",
    "                  .format(Vectorizer.get_feature_names()[indices[i,j]],indices[i,j], coefs[i,j]))\n",
    "            \n",
    "    # Print accuracy\n",
    "    print(\"\\n{}The accuracy of this model is {}{}\"\n",
    "          .format(color.BOLD,LR.score(vectorized_D, dev_labels),color.END))\n",
    "P7()\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How is the TfidfVectorizer different from the CountVectorizer?*\n",
    "\n",
    "**ANSWER:** The CountVectorizer simply counts how many times that word appears in each message. TfidfVectorizer on the other hand outputs a value that is proportional to the count of that word in the message, but also penalizes that value if the word is used in multiple messages. Therefore, it adds a layer of penalyzing commonly used words. \n",
    "\n",
    "*What kinds of mistakes is the model making? Suggest a way to address one particular issue that you see.*\n",
    "\n",
    "**ANSWER:** The first and second pieces of text are both about religion but are incorrectly labeled as computer graphics. This is probably due to the fact that the first text goes into detail of how to acquire the Book of Mormon text online and uses a lot of technical computer related words like \"ftp\", \"RTF\", \"ASCII\", \"LaTex\", etc. The first piece of text also includes the word \"file\" twice which is the 4th heavist weighted word for predicting the computer graphics label. Other than the word \"Mormon\" there aren't a lot of uniquely religious words included in that piece of text. The second text is similar where it includes words like \"ftp\", \"site\", \"online\", \"email\", \"internet\" which can fall under the computer graphics label but only the word \"Mormon\" which falls under the religion label. Because the two pieces of text include so how many technical computer terms and few religious technical terms they are mislabeled. The third piece of text is supposed to fall under the atheism label but is incorrectly labeled as religion. Just looking at the text by itself, even my human brain is unable to determine what category it should fall under. If you look at the most heavily weighted words for religion, it includes words like \"blood\", \"fbi\", \"order\" which are rather violent and militaristic. Maybe a lot of the texts used in the training set that fall under religion are very violent and militaristic in nature. Therefore I can understand why the third piece of text is mislabeled as religion.\n",
    "\n",
    "The first thing I would do is probably decrease the C value. Right now it is set to 100 which is really high and giving each of the words too much weight. I might decrease it to 1 or 0.2 as I have before. Another thing I may try is to include bigram features as well. Maybe with this, freatures like \"Book of\" and \"of Mormon\" might help label the religious texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 - Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) EXTRA CREDIT\n",
    "\n",
    "Try implementing one of your ideas based on your error analysis. Use logistic regression as your underlying model.\n",
    "\n",
    "- [1 pt] for a reasonable attempt\n",
    "- [2 pts] for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe 1st highest R value is 8.2901\u001b[0m\n",
      "The predicted probabilities are [0.076177   0.68225717 0.15926777 0.08229807]\n",
      "This means the predicted label for this message is comp.graphics\n",
      "The actual label for this message is talk.religion.misc\n",
      "The message is:\n",
      "\n",
      "Can anyone provide me a ftp site where I can obtain a online version\n",
      "of the Book of Mormon. Please email the internet address if possible.\n",
      "\n",
      "\u001b[1mThe 2nd highest R value is 5.0280\u001b[0m\n",
      "The predicted probabilities are [0.11449491 0.61250742 0.15117837 0.12181929]\n",
      "This means the predicted label for this message is comp.graphics\n",
      "The actual label for this message is talk.religion.misc\n",
      "The message is:\n",
      "\n",
      "I am pleased to announce that a *revised version* of _The Easy-to-Read Book\n",
      "of Mormon_ (former title: _Mormon's Book_) by Lynn Matthews Anderson is now\n",
      "available through anonymous ftp (see information below). In addition to the\n",
      "change in title, the revised ETR BOM has been shortened by several pages\n",
      "(eliminating many extraneous \"that's\" and \"of's\"), and many (minor) errors\n",
      "have been corrected. This release includes a simplified Joseph Smith Story,\n",
      "testimonies of the three and eight witnesses, and a \"Words-to-Know\"\n",
      "glossary.\n",
      "\n",
      "As with the previous announcement, readers are reminded that this is a\n",
      "not-for-profit endeavor. This is a copyrighted work, but people are welcome\n",
      "to make *verbatim* copies for personal use. People can recuperate the\n",
      "actual costs of printing (paper, copy center charges), but may not charge\n",
      "anything for their time in making copies, or in any way realize a profit\n",
      "from the use of this book. See the permissions notice in the book itself\n",
      "for the precise terms.\n",
      "\n",
      "Negotiations are currently underway with a Mormon publisher vis-a-vis the\n",
      "printing and distribution of bound books. (Sorry, I'm out of the wire-bound\n",
      "\"first editions.\") I will make another announcement about the availability\n",
      "of printed copies once everything has been worked out.\n",
      "\n",
      "FTP information: connect via anonymous ftp to carnot.itc.cmu.edu, then \"cd\n",
      "pub\" (you won't see anything at all until you do).\n",
      "\n",
      "\"The Easy-to-Read Book of Mormon\" is currently available in postscript and\n",
      "RTF (rich text format). (ASCII, LaTeX, and other versions can be made\n",
      "available; contact dba@andrew.cmu.edu for details.) You should be able to\n",
      "print the postscript file on any postscript printer (such as an Apple\n",
      "Laserwriter); let dba know if you have any difficulties. (The postscript in\n",
      "the last release had problems on some printers; this time it should work\n",
      "better.) RTF is a standard document interchange format that can be read in\n",
      "by a number of word processors, including Microsoft Word for both the\n",
      "Macintosh and Windows. If you don't have a postscript printer, you may be\n",
      "able to use the RTF file to print out a copy of the book.\n",
      "\n",
      "-r--r--r--  1 dba                   1984742 Apr 27 13:12 etrbom.ps\n",
      "-r--r--r--  1 dba                   1209071 Apr 27 13:13 etrbom.rtf\n",
      "\n",
      "For more information about how this project came about, please refer to my\n",
      "article in the current issue of _Sunstone_, entitled \"Delighting in\n",
      "Plainness: Issues Surrounding a Simple Modern English Book of Mormon.\"\n",
      "\n",
      "Send all inquiries and comments to:\n",
      "\n",
      "    Lynn Matthews Anderson\n",
      "    5806 Hampton Street\n",
      "    Pittsburgh, PA 15206\n",
      "\n",
      "\u001b[1mThe 3rd highest R value is 4.2629\u001b[0m\n",
      "The predicted probabilities are [0.12739287 0.09895187 0.23059574 0.54305952]\n",
      "This means the predicted label for this message is talk.religion.misc\n",
      "The actual label for this message is alt.atheism\n",
      "The message is:\n",
      "\n",
      "With the Southern Baptist Convention convening this June to consider\n",
      "the charges that Freemasonry is incompatible with christianity, I thought\n",
      "the following quotes by Mr. James Holly, the Anti-Masonic Flag Carrier,\n",
      "would amuse you all...\n",
      "\n",
      "     The following passages are exact quotes from \"The Southern \n",
      "Baptist Convention and Freemasonry\" by James L. Holly, M.D., President\n",
      "of Mission and Ministry To Men, Inc., 550 N 10th St., Beaumont, TX \n",
      "77706. \n",
      " \n",
      "     The inside cover of the book states: \"Mission & Ministry to Men, \n",
      "Inc. hereby grants permission for the reproduction of part or all of \n",
      "this booklet with two provisions: one, the material is not changed and\n",
      "two, the source is identified.\" I have followed these provisions. \n",
      "  \n",
      "     \"Freemasonry is one of the allies of the Devil\" Page iv. \n",
      " \n",
      "     \"The issue here is not moderate or conservative, the issue is God\n",
      "and the Devil\" Page vi.\" \n",
      " \n",
      "     \"It is worthwhile to remember that the formulators of public \n",
      "school education in America were Freemasons\" Page 29. \n",
      " \n",
      "     \"Jesus Christ never commanded toleration as a motive for His \n",
      "disciples, and toleration is the antithesis of the Christian message.\"\n",
      "Page 30. \n",
      " \n",
      "     \"The central dynamic of the Freemason drive for world unity \n",
      "through fraternity, liberty and equality is toleration. This is seen \n",
      "in the writings of the 'great' writers of Freemasonry\". Page 31. \n",
      " \n",
      "     \"He [Jesus Christ] established the most sectarian of all possible \n",
      "faiths.\" Page 37. \n",
      " \n",
      "     \"For narrowness and sectarianism, there is no equal to the Lord \n",
      "Jesus Christ\". Page 40. \n",
      " \n",
      "     \"What seems so right in the interest of toleration and its \n",
      "cousins-liberty, equality and fraternity-is actually one of the \n",
      "subtlest lies of the 'father of lies.'\" Page 40. \n",
      " \n",
      "     \"The Southern Baptist Convention has many churches which were \n",
      "founded in the Lodge and which have corner stones dedicated by the \n",
      "Lodge. Each of these churches should hold public ceremonies of \n",
      "repentance and of praying the blood and the Name of the Lord Jesus \n",
      "Christ over the church and renouncing the oaths taken at the \n",
      "dedication of the church and/or building.\" Page 53-54.  \n",
      " \n",
      "\n",
      "\u001b[4m\u001b[1mThe highest weighted words for each label:\u001b[0m\n",
      "\u001b[1mUnder the alt.atheism label:\u001b[0m\n",
      "The word \"atheism\", with index 3866, and a coefficient of 2.1724\n",
      "The word \"religion\", with index 20430, and a coefficient of 1.9552\n",
      "The word \"islam\", with index 13668, and a coefficient of 1.8471\n",
      "The word \"atheists\", with index 3870, and a coefficient of 1.6994\n",
      "The word \"bobby\", with index 4784, and a coefficient of 1.6445\n",
      "\u001b[1mUnder the comp.graphics label:\u001b[0m\n",
      "The word \"graphics\", with index 11552, and a coefficient of 4.0387\n",
      "The word \"image\", with index 12769, and a coefficient of 2.6034\n",
      "The word \"file\", with index 10376, and a coefficient of 2.4499\n",
      "The word \"files\", with index 10379, and a coefficient of 2.1264\n",
      "The word \"3d\", with index 1145, and a coefficient of 2.0438\n",
      "\u001b[1mUnder the sci.space label:\u001b[0m\n",
      "The word \"space\", with index 22567, and a coefficient of 5.4900\n",
      "The word \"nasa\", with index 16697, and a coefficient of 2.5034\n",
      "The word \"orbit\", with index 17597, and a coefficient of 2.1782\n",
      "The word \"launch\", with index 14540, and a coefficient of 2.0102\n",
      "The word \"moon\", with index 16358, and a coefficient of 1.9233\n",
      "\u001b[1mUnder the talk.religion.misc label:\u001b[0m\n",
      "The word \"jesus\", with index 13844, and a coefficient of 2.2461\n",
      "The word \"christian\", with index 5901, and a coefficient of 2.2345\n",
      "The word \"christians\", with index 5904, and a coefficient of 1.9669\n",
      "The word \"he\", with index 11984, and a coefficient of 1.9179\n",
      "The word \"god\", with index 11399, and a coefficient of 1.6189\n",
      "\n",
      "\u001b[1mThe accuracy of this model is 0.7204142011834319\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "def P8():\n",
    "    # Create a TfidfVectorizer\n",
    "    Vectorizer = TfidfVectorizer()\n",
    "    vectorized_T = Vectorizer.fit_transform(train_data)\n",
    "    vectorized_D = Vectorizer.transform(dev_data)\n",
    "    # Create a Logistic Regression with C = 1\n",
    "    LR = LogisticRegression(C = 1)\n",
    "    LR.fit(vectorized_T, train_labels)\n",
    "    # Find the predict probabilities in for each label for each message \n",
    "    probs = LR.predict_proba(vectorized_D)\n",
    "    # Iterate through these probabilities to find the R ratio\n",
    "    Rratio = []\n",
    "    for i in range(len(probs)):\n",
    "        # Find the maximum predicted probability for this message\n",
    "        maxpredprob = np.max(probs[i])\n",
    "        # Find the correct label for this message\n",
    "        corr_label = dev_labels[i]\n",
    "        # Find the predicted probability associated of the correct label for this message\n",
    "        corrpredprob = probs[i][corr_label]\n",
    "        # Find the R ratio\n",
    "        R = maxpredprob/corrpredprob\n",
    "        Rratio.append(R)\n",
    "    # Find the top 3 R ratios and their indices\n",
    "    TopRs = np.sort(Rratio)[::-1][:3]\n",
    "    TopRsIndex = np.argsort(Rratio)[::-1][:3]\n",
    "    labels = newsgroups_train.target_names\n",
    "    \n",
    "    for i in range(3):\n",
    "        order = [\"1st\",\"2nd\",\"3rd\"]\n",
    "        print(\"{}The {} highest R value is {:.4f}{}\".format(color.BOLD,order[i],TopRs[i],color.END))\n",
    "        predprobs = probs[TopRsIndex[i]]\n",
    "        print(\"The predicted probabilities are {}\".format(predprobs))\n",
    "        print(\"This means the predicted label for this message is {}\".format(labels[np.argmax(predprobs)]))\n",
    "        print(\"The actual label for this message is {}\".format(labels[dev_labels[TopRsIndex[i]]]))\n",
    "        print(\"The message is:\\n\\n{}\\n\".format(dev_data[TopRsIndex[i]]))\n",
    "    \n",
    "    indices = np.argsort(LR.coef_, axis = 1)[:,::-1][:,0:5]\n",
    "    coefs = np.sort(LR.coef_, axis = 1)[:,::-1][:,0:5]\n",
    "    \n",
    "    # Print out the 5 parameters for each label\n",
    "    print(\"{}{}The highest weighted words for each label:{}\".format(color.UNDERLINE,color.BOLD,color.END))\n",
    "    for i in range(4):\n",
    "        print(\"{}Under the {} label:{}\".format(color.BOLD,labels[i],color.END))\n",
    "        for j in range(5):\n",
    "            print(\"The word \\\"{}\\\", with index {}, and a coefficient of {:.4f}\"\n",
    "                  .format(Vectorizer.get_feature_names()[indices[i,j]],indices[i,j], coefs[i,j]))\n",
    "            \n",
    "    # Print accuracy\n",
    "    print(\"\\n{}The accuracy of this model is {}{}\"\n",
    "          .format(color.BOLD,LR.score(vectorized_D, dev_labels),color.END))\n",
    "P8()\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** When you decrease the C value to 1, the accuracy drops to 0.7204 (0.0429 decrease) which is not great. The R ratios are also decreased a lot which is an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe 1st highest R value is 693.9734\u001b[0m\n",
      "The predicted probabilities are [0.00416965 0.98963835 0.00476595 0.00142605]\n",
      "This means the predicted label for this message is comp.graphics\n",
      "The actual label for this message is talk.religion.misc\n",
      "The message is:\n",
      "\n",
      "I am pleased to announce that a *revised version* of _The Easy-to-Read Book\n",
      "of Mormon_ (former title: _Mormon's Book_) by Lynn Matthews Anderson is now\n",
      "available through anonymous ftp (see information below). In addition to the\n",
      "change in title, the revised ETR BOM has been shortened by several pages\n",
      "(eliminating many extraneous \"that's\" and \"of's\"), and many (minor) errors\n",
      "have been corrected. This release includes a simplified Joseph Smith Story,\n",
      "testimonies of the three and eight witnesses, and a \"Words-to-Know\"\n",
      "glossary.\n",
      "\n",
      "As with the previous announcement, readers are reminded that this is a\n",
      "not-for-profit endeavor. This is a copyrighted work, but people are welcome\n",
      "to make *verbatim* copies for personal use. People can recuperate the\n",
      "actual costs of printing (paper, copy center charges), but may not charge\n",
      "anything for their time in making copies, or in any way realize a profit\n",
      "from the use of this book. See the permissions notice in the book itself\n",
      "for the precise terms.\n",
      "\n",
      "Negotiations are currently underway with a Mormon publisher vis-a-vis the\n",
      "printing and distribution of bound books. (Sorry, I'm out of the wire-bound\n",
      "\"first editions.\") I will make another announcement about the availability\n",
      "of printed copies once everything has been worked out.\n",
      "\n",
      "FTP information: connect via anonymous ftp to carnot.itc.cmu.edu, then \"cd\n",
      "pub\" (you won't see anything at all until you do).\n",
      "\n",
      "\"The Easy-to-Read Book of Mormon\" is currently available in postscript and\n",
      "RTF (rich text format). (ASCII, LaTeX, and other versions can be made\n",
      "available; contact dba@andrew.cmu.edu for details.) You should be able to\n",
      "print the postscript file on any postscript printer (such as an Apple\n",
      "Laserwriter); let dba know if you have any difficulties. (The postscript in\n",
      "the last release had problems on some printers; this time it should work\n",
      "better.) RTF is a standard document interchange format that can be read in\n",
      "by a number of word processors, including Microsoft Word for both the\n",
      "Macintosh and Windows. If you don't have a postscript printer, you may be\n",
      "able to use the RTF file to print out a copy of the book.\n",
      "\n",
      "-r--r--r--  1 dba                   1984742 Apr 27 13:12 etrbom.ps\n",
      "-r--r--r--  1 dba                   1209071 Apr 27 13:13 etrbom.rtf\n",
      "\n",
      "For more information about how this project came about, please refer to my\n",
      "article in the current issue of _Sunstone_, entitled \"Delighting in\n",
      "Plainness: Issues Surrounding a Simple Modern English Book of Mormon.\"\n",
      "\n",
      "Send all inquiries and comments to:\n",
      "\n",
      "    Lynn Matthews Anderson\n",
      "    5806 Hampton Street\n",
      "    Pittsburgh, PA 15206\n",
      "\n",
      "\u001b[1mThe 2nd highest R value is 239.2825\u001b[0m\n",
      "The predicted probabilities are [0.94595266 0.01567781 0.03441625 0.00395329]\n",
      "This means the predicted label for this message is alt.atheism\n",
      "The actual label for this message is talk.religion.misc\n",
      "The message is:\n",
      "\n",
      "In <1ren9a$94q@morrow.stanford.edu> salem@pangea.Stanford.EDU (Bruce Salem) \n",
      "\n",
      "\n",
      "\n",
      "This brings up another something I have never understood.  I asked this once\n",
      "before and got a few interesting responses, but somehow didn't seem satisfied.\n",
      "Why would the NT NOT be considered a good source.  This might be a \n",
      "literary/historical question, but when I studied history I always looked for \n",
      "firsthand original sources to write my papers.  If the topic was on Mr. X, I \n",
      "looked to see if Mr. X wrote anything about it.  If the topic was on a group, \n",
      "look for the group, etc.  If the topic is on Mr. X, and Mr. X did not write \n",
      "anything about it, (barring the theistic response about the Bible being \n",
      "divinely inspired which I can't adequately argue), wouldn't we look for people\n",
      "who ate, worked, walked, talked, etc. with him?  If someone was at an event \n",
      "wouldn't they be a better \"reporter\" than someone who heard about it second \n",
      "hand?  I guess isn't firsthand better than second hand.  I know, there is bias,\n",
      "and winners writing history, but doesn't the principle of firsthand being best\n",
      "still apply?\n",
      "\n",
      "MAC\n",
      "--\n",
      "****************************************************************\n",
      "                                                    Michael A. Cobb\n",
      " \"...and I won't raise taxes on the middle     University of Illinois\n",
      "    class to pay for my programs.\"                 Champaign-Urbana\n",
      "          -Bill Clinton 3rd Debate             cobb@alexia.lis.uiuc.edu\n",
      "\n",
      "\u001b[1mThe 3rd highest R value is 154.6642\u001b[0m\n",
      "The predicted probabilities are [0.0137269  0.96486041 0.01517427 0.00623842]\n",
      "This means the predicted label for this message is comp.graphics\n",
      "The actual label for this message is talk.religion.misc\n",
      "The message is:\n",
      "\n",
      "Can anyone provide me a ftp site where I can obtain a online version\n",
      "of the Book of Mormon. Please email the internet address if possible.\n",
      "\n",
      "\u001b[4m\u001b[1mThe highest weighted words for each label:\u001b[0m\n",
      "\u001b[1mUnder the alt.atheism label:\u001b[0m\n",
      "The word \"atheism\", with index 27470, and a coefficient of 8.3724\n",
      "The word \"religion\", with index 159848, and a coefficient of 7.5090\n",
      "The word \"islam\", with index 102526, and a coefficient of 6.7860\n",
      "The word \"atheists\", with index 27652, and a coefficient of 6.5367\n",
      "The word \"bobby\", with index 35299, and a coefficient of 5.8556\n",
      "\u001b[1mUnder the comp.graphics label:\u001b[0m\n",
      "The word \"graphics\", with index 83730, and a coefficient of 14.2197\n",
      "The word \"image\", with index 93558, and a coefficient of 9.3554\n",
      "The word \"file\", with index 72680, and a coefficient of 8.6205\n",
      "The word \"3d\", with index 5626, and a coefficient of 7.5441\n",
      "The word \"computer\", with index 47737, and a coefficient of 7.4679\n",
      "\u001b[1mUnder the sci.space label:\u001b[0m\n",
      "The word \"space\", with index 175454, and a coefficient of 19.7562\n",
      "The word \"nasa\", with index 126253, and a coefficient of 8.4199\n",
      "The word \"orbit\", with index 139415, and a coefficient of 8.1857\n",
      "The word \"launch\", with index 109362, and a coefficient of 7.4689\n",
      "The word \"moon\", with index 122895, and a coefficient of 6.5448\n",
      "\u001b[1mUnder the talk.religion.misc label:\u001b[0m\n",
      "The word \"christian\", with index 43540, and a coefficient of 8.6863\n",
      "The word \"christians\", with index 43745, and a coefficient of 7.0650\n",
      "The word \"jesus\", with index 104655, and a coefficient of 6.8700\n",
      "The word \"fbi\", with index 71757, and a coefficient of 5.8013\n",
      "The word \"god\", with index 82256, and a coefficient of 5.3976\n",
      "\n",
      "\u001b[1mThe accuracy of this model is 0.7677514792899408\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### STUDENT START ###\n",
    "def P8():\n",
    "    # Create a TfidfVectorizer with unigram and bigram features\n",
    "    Vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "    vectorized_T = Vectorizer.fit_transform(train_data)\n",
    "    vectorized_D = Vectorizer.transform(dev_data)\n",
    "    # Create a Logistic Regression with C = 100\n",
    "    LR = LogisticRegression(C = 100)\n",
    "    LR.fit(vectorized_T, train_labels)\n",
    "    # Find the predict probabilities in for each label for each message \n",
    "    probs = LR.predict_proba(vectorized_D)\n",
    "    # Iterate through these probabilities to find the R ratio\n",
    "    Rratio = []\n",
    "    for i in range(len(probs)):\n",
    "        # Find the maximum predicted probability for this message\n",
    "        maxpredprob = np.max(probs[i])\n",
    "        # Find the correct label for this message\n",
    "        corr_label = dev_labels[i]\n",
    "        # Find the predicted probability associated of the correct label for this message\n",
    "        corrpredprob = probs[i][corr_label]\n",
    "        # Find the R ratio\n",
    "        R = maxpredprob/corrpredprob\n",
    "        Rratio.append(R)\n",
    "    # Find the top 3 R ratios and their indices\n",
    "    TopRs = np.sort(Rratio)[::-1][:3]\n",
    "    TopRsIndex = np.argsort(Rratio)[::-1][:3]\n",
    "    labels = newsgroups_train.target_names\n",
    "    \n",
    "    for i in range(3):\n",
    "        order = [\"1st\",\"2nd\",\"3rd\"]\n",
    "        print(\"{}The {} highest R value is {:.4f}{}\".format(color.BOLD,order[i],TopRs[i],color.END))\n",
    "        predprobs = probs[TopRsIndex[i]]\n",
    "        print(\"The predicted probabilities are {}\".format(predprobs))\n",
    "        print(\"This means the predicted label for this message is {}\".format(labels[np.argmax(predprobs)]))\n",
    "        print(\"The actual label for this message is {}\".format(labels[dev_labels[TopRsIndex[i]]]))\n",
    "        print(\"The message is:\\n\\n{}\\n\".format(dev_data[TopRsIndex[i]]))\n",
    "    \n",
    "    indices = np.argsort(LR.coef_, axis = 1)[:,::-1][:,0:5]\n",
    "    coefs = np.sort(LR.coef_, axis = 1)[:,::-1][:,0:5]\n",
    "    \n",
    "    # Print out the 5 parameters for each label\n",
    "    print(\"{}{}The highest weighted words for each label:{}\".format(color.UNDERLINE,color.BOLD,color.END))\n",
    "    for i in range(4):\n",
    "        print(\"{}Under the {} label:{}\".format(color.BOLD,labels[i],color.END))\n",
    "        for j in range(5):\n",
    "            print(\"The word \\\"{}\\\", with index {}, and a coefficient of {:.4f}\"\n",
    "                  .format(Vectorizer.get_feature_names()[indices[i,j]],indices[i,j], coefs[i,j]))\n",
    "            \n",
    "    # Print accuracy\n",
    "    print(\"\\n{}The accuracy of this model is {}{}\"\n",
    "          .format(color.BOLD,LR.score(vectorized_D, dev_labels),color.END))\n",
    "P8()\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** When you include bigram features in the model, the accuracy actually improved to 0.7678 (0.0045 improvement). Furthermore, the R ratios are also smaller which is also an improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
