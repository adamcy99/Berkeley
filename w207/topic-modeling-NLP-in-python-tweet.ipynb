{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling and Natural Language Processing with Twitter Data\n",
    "\n",
    "##  Jason Anastasopoulos\n",
    "##  December 4, 2018\n",
    "### Email: ljanastas@uga.edu\n",
    "\n",
    "The code below provides a brief introduction on acquiring Twitter data using the twitter API via Python. For this exercise I will be acquiring Donald Trump's tweets and will try to figure out what the topics his tweets are using the Latent Dirichlet Allocation  Topic Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os,re,csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import twitter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we enter our Twitter credentials. These can be acquired through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'twitter' has no attribute 'Api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-427c7a575662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m api = twitter.Api(consumer_key='4NHHnFAx6AwbhipaG0aGJ2P16',\n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0mconsumer_secret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RKhXZANu7SnXKrtHUw5K276jJbg5Y8i3tDyn2c9YmcVNpQBevc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0maccess_token_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'18249358-tUB1Pg2HDDJtIKAwanfMYk379yFsDLOTLEQBPTaLG'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       access_token_secret='zoaYBorszhARknoaEsfT5l7pDogvTSINKOV0a0EboMFNk')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'twitter' has no attribute 'Api'"
     ]
    }
   ],
   "source": [
    "api = twitter.Api(consumer_key='4NHHnFAx6AwbhipaG0aGJ2P16',\n",
    "                      consumer_secret='RKhXZANu7SnXKrtHUw5K276jJbg5Y8i3tDyn2c9YmcVNpQBevc',\n",
    "                      access_token_key='18249358-tUB1Pg2HDDJtIKAwanfMYk379yFsDLOTLEQBPTaLG',\n",
    "                      access_token_secret='zoaYBorszhARknoaEsfT5l7pDogvTSINKOV0a0EboMFNk')\n",
    "\n",
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search the Twitter API using keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070159200641302529, u'RT @USAElectionInfo: Republican Brad Raffensperger has defeated Democrat John Barrow in the runoff election for Georgia Secretary of State.')\n",
      "(1070159162208710656, u'RT @Greg_Palast: For example... Rahiem Shabazz, who found himself on the #Georgia purge list we made public, is still not listed as registe\\u2026')\n",
      "(1070159129317134336, u\"RT @alexsalvinews: #BREAKING on @OANN: Republican Brad Raffensperger has defeated former Democratic congressman John Barrow in Georgia's ru\\u2026\")\n",
      "(1070159107196416001, u'RT @voxdotcom: Republican Brad Raffensperger has won the race for Georgia\\u2019s next secretary of state.\\n\\nHe\\u2019ll be responsible for responding t\\u2026')\n",
      "(1070159090452639745, u\"RT @alexsalvinews: #BREAKING on @OANN: Republican Brad Raffensperger has defeated former Democratic congressman John Barrow in Georgia's ru\\u2026\")\n",
      "(1070159076053667840, u'RT @nytimes: Georgia secretary of state live election results https://t.co/5OPkvSAcyF')\n",
      "(1070159057862955008, u'Republicans win both runoff races in Georgia !!!\\n\\nSecretary of State and Public Service Commission !!!')\n",
      "(1070159051827363841, u'AP declares Raffensperger the winner over Barrow in Georgia Sec of State via AJC https://t.co/wvwe6EcjC3 #gapol')\n",
      "(1070159040469057536, u'#BREAKING on @OANN: Republican Brad Raffensperger has defeated former Democratic congressman John Barrow in Georgia\\u2026 https://t.co/35yWlZFs7A')\n",
      "(1070158944641933312, u'Republican Brad Raffensperger wins Georgia secretary of state runoff https://t.co/JHecSCQRWH Thank you\\u2026 https://t.co/B972E3uTUT')\n",
      "(1070158885489729537, u'RT @newtgingrich: Make sure all your friends vote for Brad Raffensperger for Georgia Secretary of State tuesday. He will do a great job and\\u2026')\n",
      "(1070158870239035392, u'RT @Greg_Palast: Today there are two absolutely vital elections in #Georgia. The runoff for Secretary of State and the runoff for the publi\\u2026')\n",
      "(1070158763301072898, u\"RT @Greg_Palast: #Thread on #Georgia's runoff for the Public Service Commission \\u2014 one of those offices you don't think much about. https://\\u2026\")\n",
      "(1070158723165769728, u'RT @Greg_Palast: #Georgia Secretary of State runoff marred by allegations of continued #VoterSuppression \\u2014 thousands of wrongly purged vote\\u2026')\n",
      "(1070158720632541185, u'How does a state vote for a #secretaryofstate from the same party that has numerous legal problems and #vote tamper\\u2026 https://t.co/miTRaIhhdm')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = api.GetSearch(\"Runoff Georgia\") # Replace happy with your search\n",
    "for tweet in search:\n",
    "    print(tweet.id, tweet.text)\n",
    "    \n",
    "len(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python twitter library has a lot of cool functions that you can use and learn about through the help() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method GetUserTimeline in module twitter.api:\n",
      "\n",
      "GetUserTimeline(self, user_id=None, screen_name=None, since_id=None, max_id=None, count=None, include_rts=True, trim_user=False, exclude_replies=False) method of twitter.api.Api instance\n",
      "    Fetch the sequence of public Status messages for a single user.\n",
      "    \n",
      "    The twitter.Api instance must be authenticated if the user is private.\n",
      "    \n",
      "    Args:\n",
      "      user_id (int, optional):\n",
      "        Specifies the ID of the user for whom to return the\n",
      "        user_timeline. Helpful for disambiguating when a valid user ID\n",
      "        is also a valid screen name.\n",
      "      screen_name (str, optional):\n",
      "        Specifies the screen name of the user for whom to return the\n",
      "        user_timeline. Helpful for disambiguating when a valid screen\n",
      "        name is also a user ID.\n",
      "      since_id (int, optional):\n",
      "        Returns results with an ID greater than (that is, more recent\n",
      "        than) the specified ID. There are limits to the number of\n",
      "        Tweets which can be accessed through the API. If the limit of\n",
      "        Tweets has occurred since the since_id, the since_id will be\n",
      "        forced to the oldest ID available.\n",
      "      max_id (int, optional):\n",
      "        Returns only statuses with an ID less than (that is, older\n",
      "        than) or equal to the specified ID.\n",
      "      count (int, optional):\n",
      "        Specifies the number of statuses to retrieve. May not be\n",
      "        greater than 200.\n",
      "      include_rts (bool, optional):\n",
      "        If True, the timeline will contain native retweets (if they\n",
      "        exist) in addition to the standard stream of tweets.\n",
      "      trim_user (bool, optional):\n",
      "        If True, statuses will only contain the numerical user ID only.\n",
      "        Otherwise a full user object will be returned for each status.\n",
      "      exclude_replies (bool, optional)\n",
      "        If True, this will prevent replies from appearing in the returned\n",
      "        timeline. Using exclude_replies with the count parameter will mean you\n",
      "        will receive up-to count tweets - this is because the count parameter\n",
      "        retrieves that many tweets before filtering out retweets and replies.\n",
      "        This parameter is only supported for JSON and XML responses.\n",
      "    \n",
      "    Returns:\n",
      "      A sequence of Status instances, one for each message up to count\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(api.GetUserTimeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'.....China does not want Tariffs!',\n",
       " u'We are either going to have a REAL DEAL with China, or no deal at all - at which point we will be charging major Ta\\u2026 https://t.co/JIqNBYOxT8',\n",
       " u'....in the world. I want clean air and clean water and have been making great strides in improving America\\u2019s enviro\\u2026 https://t.co/iQ4aLjD0Kb',\n",
       " u'I am glad that my friend @EmmanuelMacron and the protestors in Paris have agreed with the conclusion I reached two\\u2026 https://t.co/YcxKsnDGwt',\n",
       " u'RT @charliekirk11: There are riots in socialist France because of radical leftist fuel taxes\\n\\nMedia barely mentioning this\\n\\nAmerica is boom\\u2026',\n",
       " u'Could somebody please explain to the Democrats (we need their votes) that our Country losses 250 Billion Dollars a\\u2026 https://t.co/Z8nKReskdg',\n",
       " u'.....But if a fair deal is able to be made with China, one that does all of the many things we know must be finally\\u2026 https://t.co/VMfAQjVXmz',\n",
       " u'....I am a Tariff Man. When people or countries come in to raid the great wealth of our Nation, I want them to pay\\u2026 https://t.co/fj8Bwjgywu',\n",
       " u'......on seeing whether or not a REAL deal with China is actually possible. If it is, we will get it done. China is\\u2026 https://t.co/GVhX7U9ZQF',\n",
       " u'The negotiations with China have already started. Unless extended, they will end 90 days from the date of our wonde\\u2026 https://t.co/iYphE2px2L']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = api.GetUserTimeline(screen_name=\"realDonaldTrump\", count=5000)\n",
    "tweets = [i.AsDict() for i in t]\n",
    "\n",
    "tweettext = [i[\"text\"] for i in tweets]\n",
    "\n",
    "len(tweettext)\n",
    "\n",
    "tweettext[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## So far so good not lets clean this up ###\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are pre-processing the text by creating a tokenizer that splits the documents up into tokens (words or phrases), creating a dictionary of stop words and creating a \"stemmer\" which stems the words (ie removing \"-ing\" endings etc. We also remove extraneous \"bill related\" words such as \"propXX_XXXX\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'either',\n",
       " u'go',\n",
       " u'real',\n",
       " u'deal',\n",
       " u'china',\n",
       " u'deal',\n",
       " u'point',\n",
       " u'will',\n",
       " u'charg',\n",
       " u'major',\n",
       " u'ta',\n",
       " u'co',\n",
       " u'jiqnbyoxt8']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tweettext:\n",
    "    #print \"Processing\",i\n",
    "    # clean and tokenize document string\n",
    "    tokens = tokenizer.tokenize(i)\n",
    "    # remove all numbers\n",
    "    tokens = [x for x in tokens if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())]\n",
    "    # remove structural words\n",
    "    tokens = [x for x in tokens if len(x) > 1]\n",
    "    tokens = [x.lower() for x in tokens]\n",
    "    tokens = [x for x in tokens if 'http' not in x]\n",
    "    tokens = [x for x in tokens if x not in \"_\"]\n",
    "    tokens = [x for x in tokens if x not in 'rt']\n",
    "    tokens = [x for x in tokens if x not in \".co\"]\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "dictionaryall = corpora.Dictionary(texts)\n",
    "\n",
    "corpusall = [dictionaryall.doc2bow(text) for text in texts]\n",
    "\n",
    "texts[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'.....China does not want Tariffs!',\n",
       " u'We are either going to have a REAL DEAL with China, or no deal at all - at which point we will be charging major Ta\\u2026 https://t.co/JIqNBYOxT8',\n",
       " u'....in the world. I want clean air and clean water and have been making great strides in improving America\\u2019s enviro\\u2026 https://t.co/iQ4aLjD0Kb',\n",
       " u'I am glad that my friend @EmmanuelMacron and the protestors in Paris have agreed with the conclusion I reached two\\u2026 https://t.co/YcxKsnDGwt',\n",
       " u'RT @charliekirk11: There are riots in socialist France because of radical leftist fuel taxes\\n\\nMedia barely mentioning this\\n\\nAmerica is boom\\u2026',\n",
       " u'Could somebody please explain to the Democrats (we need their votes) that our Country losses 250 Billion Dollars a\\u2026 https://t.co/Z8nKReskdg',\n",
       " u'.....But if a fair deal is able to be made with China, one that does all of the many things we know must be finally\\u2026 https://t.co/VMfAQjVXmz',\n",
       " u'....I am a Tariff Man. When people or countries come in to raid the great wealth of our Nation, I want them to pay\\u2026 https://t.co/fj8Bwjgywu',\n",
       " u'......on seeing whether or not a REAL deal with China is actually possible. If it is, we will get it done. China is\\u2026 https://t.co/GVhX7U9ZQF',\n",
       " u'The negotiations with China have already started. Unless extended, they will end 90 days from the date of our wonde\\u2026 https://t.co/iYphE2px2L']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweettext[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs tokenization, stop word removal and number removal and places the corpora into a clean list that will be ready for analysis using the Latent Dirichlet Allocation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate LDA model\n",
    "ldamodelall = gensim.models.ldamodel.LdaModel(corpusall, num_topics=5, \n",
    "                                              id2word = dictionaryall, passes=20,\n",
    "                                              minimum_probability=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above estimates a 5 topic topic model using Trump's tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.018*\"great\" + 0.013*\"will\" + 0.012*\"co\" + 0.011*\"amp\" + 0.011*\"one\"'), (1, u'0.023*\"great\" + 0.018*\"big\" + 0.014*\"america\" + 0.014*\"billion\" + 0.012*\"vote\"'), (2, u'0.027*\"presid\" + 0.019*\"will\" + 0.018*\"trump\" + 0.013*\"year\" + 0.012*\"great\"'), (3, u'0.020*\"will\" + 0.013*\"china\" + 0.013*\"peopl\" + 0.011*\"mueller\" + 0.011*\"co\"'), (4, u'0.020*\"look\" + 0.016*\"will\" + 0.011*\"presid\" + 0.010*\"thank\" + 0.009*\"co\"')]\n"
     ]
    }
   ],
   "source": [
    "# First 25 are the Chamber of Commerce Bills Remaining are the propositions so...\n",
    "\n",
    "print(ldamodelall.print_topics(num_topics=5, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints the first 5 topics from the full model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the topic here?\n",
    "\n",
    "### Topic 1: great, will, co, amp, one -- Label: ?\n",
    "### Topic 2: great, big, america, billion, vote -- Label: Election/Voting\n",
    "### Topic 3: presid, will, trump, year, great -- Label: Tweets about Trump Himself.\n",
    "### Topic 4: will, china, people, mueller, co -- Label: Sources of Trump's Angst.\n",
    "### Topic 5: look, will, presid, thank, co -- Label: Tweets about Trump Himself II/Thankfulness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out the distribution over topics for a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'I will be in Gulfport and Tupelo, Mississippi, on Monday night doing two Rallies for Senator Hyde-Smith, who has a\\u2026 https://t.co/DD7Am2nSiZ'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweettext[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.014593961121284617),\n",
       " (1, 0.014551081943241893),\n",
       " (2, 0.014403287005103337),\n",
       " (3, 0.014410350785019746),\n",
       " (4, 0.9420413191453505)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodelall[corpusall[100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout Session Exercise\n",
    "\n",
    "1. Collect and process all tweets from Berkeley's School of Information Account: @BerkeleyISchool.\n",
    "\n",
    "2. Estimate a 5-topic topic model and label each of the topics.\n",
    "\n",
    "3. Label one of the tweets using the topic distribution. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
