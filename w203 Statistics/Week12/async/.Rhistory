library(car)
library(lmtest)
library(sandwich)
library(stargazer)
load("Wage1.rdata")
# We gain an overview using a scatterplot matrix.
scatterplotMatrix(data[ , c("wage", "educ", "exper")])
hist(data$educ, breaks = 0:20-.5,
main = "Years of Education", xlab = NULL)
hist(data$exper, breaks = 1:52-.5,
main = "Years of Potential Experience", xlab = NULL)
model1 = lm(wage ~ educ + exper, data = data)
e
model1 = lm(wage ~ educ + exper, data = data)
summary(model1)
summary(model1)
# get the residual vs. fitted value and scale-location plot
plot(model1)
shapiro.test(model1$residuals)
# We can confirm the presense of heteroskedasticity with
# a Breusch-Pagan test.  Be careful to consider the sample
# size when interpreting this test.
bptest(model1)
# There are other tools we can use to assess the CLM assumptions.
# For normality of errors, we can examine the residuals directly.
hist(model1$residuals, breaks = 50)
# We might also consider the formal Shapiro-Wilk test of normality.
shapiro.test(model1$residuals)
# We can confirm the presense of heteroskedasticity with
# a Breusch-Pagan test.  Be careful to consider the sample
# size when interpreting this test.
bptest(model1)
# To address heteroskedasticity, we use robust standard errors.
coeftest(model1, vcov = vcovHC)
vcovHC(model1)
model2 = lm(log(wage) ~ educ + exper, data = data)
plot(model2)
# We need the vectors of robust standard errors.
# We can get these from the coeftest output
(se.model1 = coeftest(model1, vcov = vcovHC)[ , "Std. Error"])
(se.model1 = sqrt(diag(vcovHC(model1))))
(se.model2 = sqrt(diag(vcovHC(model2))))
# We pass the standard errors into stargazer through
# the se argument.
stargazer(model1, model2, type = "text", omit.stat = "f",
se = list(se.model1, se.model2),
star.cutoffs = c(0.05, 0.01, 0.001))
