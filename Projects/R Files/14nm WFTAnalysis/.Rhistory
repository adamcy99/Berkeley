USwft <- wft[wft$FAMILY_CODE == "US",]
View(wft)
library(car)
library(reshape2)
library(ggplot2)
library(sandwich)
library(stargazer)
library(lmtest)
#scatterplotMatrix(wft[3:7], c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly"))
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly, data = wft)
hist(wft$fin_res_metric2)
# Create model for 8-24c yield vs. only dg and sail yield.
model1 <- lm(wft8to24 ~ dgvmax+sailvmax, data = wft)
# Residuals-Fitted Values plot (Zero Conditional Mean)
plot(model1, 1)
# Scale-Location plot (Homoskedasticity)
plot(model1, 3)
# Breusch-Pagan Test for Homoskedasticity
bptest(model1)
# Q-Q Plot (Normality of Residuals)
plot(model1, 2)
# Shapiro-Wilk test of normality
shapiro.test(model1$residuals)
# Histogram of Residuals
hist(model1$residuals)
# Residuals-Leverage plot
plot(model1, 5) # No problem with Cook's distance
# a general rule is that if 1 % (or more) data points have standardized residuals > 2.5, the model contains too much error. If 5% (or more) of data points have residuals > 2, the model has too much error and represents our data poorly.
a <- rstudent(model1)
b <- a[a < -3]
#linearHypothesis(model1, c("dgvmax = 0", " sailvmax = 0"), vcov = vcovHC)
linearHypothesis(model1, c("dgvmax = 0", " sailvmax = 0"))
paste("adj.r.square:", summary(model1)$adj.r.squared)
coeftest(model1)
model <- lm(wft8to24 ~ dgvmax+sailvmax+sailvmin_ly+fin_res_metric2, data = wft)
plot(model)
model$coefficients
sd(wft$wft8to24)
summary(model)$adj.r.square
USmodel <- lm(wft8to24 ~ dgvmax+sailvmax+sailvmin_ly+fin_res_metric2, data = USwft)
plot(USmodel)
USmodel$coefficients
USmodel2 <- lm(wft22to24 ~ dgvmax+sailvmax+sailvmin_ly+fin_res_metric2, data = USwft)
plot(USmodel2)
USmodel2$coefficients
View(wft)
knitr::opts_chunk$set(echo = TRUE)
#scatterplotMatrix(wft[3:7], c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly"))
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly+fin_res_metric2, data = wft)
setwd("~/Desktop/WFTAnalysis/")
getwd()
# Pull csv file and create wft df
wft <- read.csv("WFT.csv")
# Change column names for easier calls
colnames(wft)[3:7] <- c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly")
# Convert wft yields to percentage values
wft$wft8to24 <- wft$wft8to24*100
wft$wft22to24 <- wft$wft22to24*100
# Create USwft df for only US wafers
USwft <- wft[wft$FAMILY_CODE == "US",]
library(car)
library(reshape2)
library(ggplot2)
library(sandwich)
library(stargazer)
library(lmtest)
#scatterplotMatrix(wft[3:7], c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly"))
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly+fin_res_metric2, data = wft)
hist(wft$fin_res_metric2)
#scatterplotMatrix(wft[3:7], c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly"))
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly, data = wft)
hist(wft$fin_res_metric2)
#scatterplotMatrix(wft[3:7], c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly"))
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly, data = wft)
hist(wft$fin_res_metric2)
cor_dr = cor(wft[cc("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly", "fin_res_metric2")],
use = "complete.obs")
#scatterplotMatrix(wft[3:7], c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly"))
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly, data = wft)
hist(wft$fin_res_metric2)
cor_dr = cor(wft[c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly", "fin_res_metric2")],
use = "complete.obs")
View(cor_dr)
#scatterplotMatrix(wft[3:7], c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly"))
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly, data = wft)
hist(wft$fin_res_metric2)
cor(wft[c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly", "fin_res_metric2")],
use = "complete.obs")
# Scatter Plot Matrix
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly, data = wft)
hist(wft$log(fin_res_metric2))
# Scatter Plot Matrix
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly, data = wft)
hist(log(wft$fin_res_metric2))
# Correlation Table
cor(wft[c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly", "fin_res_metric2")],
use = "complete.obs")
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop")
getwd()
df <- read.csv("hotphos.csv")
hotphos = df[df$X14HP_ExtendedHotPhos == "Yes",]
blank = df[df$X14HP_ExtendedHotPhos == "No",]
FQD4 = df[df$Tool == "FQD4",]
FQD5 = df[df$Tool == "FQD5",]
length(hotphos$fin_res_metric2)
length(blank$fin_res_metric2)
summary(blank$fin_res_metric2)
summary(hotphos$fin_res_metric2)
t.test(hotphos$fin_res_metric2,  mu = mean(blank$fin_res_metric2))
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop")
getwd()
df <- read.csv("hotphos.csv")
hotphos = df[df$X14HP_ExtendedHotPhos == "Yes",]
blank = df[df$X14HP_ExtendedHotPhos == "No",]
FQD4 = df[df$Tool == "FQD4",]
FQD5 = df[df$Tool == "FQD5",]
length(hotphos$fin_res_metric2)
length(blank$fin_res_metric2)
summary(blank$fin_res_metric2)
summary(hotphos$fin_res_metric2)
t.test(hotphos$fin_res_metric2,  mu = mean(blank$fin_res_metric2))
FQD4hotphos = hotphos[hotphos$Tool == "FQD4",]
FQD4blank = blank[blank$Tool == "FQD4",]
length(FQD4hotphos$fin_res_metric2)
length(FQD4blank$fin_res_metric2)
summary(FQD4blank$fin_res_metric2)
summary(FQD4hotphos$fin_res_metric2)
t.test(FQD4hotphos$fin_res_metric2,  mu = mean(FQD4blank$fin_res_metric2))
t.test(FQD4blank$fin_res_metric2, mu = mean(FQD4hotphos$fin_res_metric2))
FQD5hotphos = hotphos[hotphos$Tool == "FQD5",]
FQD5blank = blank[blank$Tool == "FQD5",]
length(FQD5hotphos$fin_res_metric2)
length(FQD5blank$fin_res_metric2)
summary(FQD5blank$fin_res_metric2)
summary(FQD5hotphos$fin_res_metric2)
t.test(FQD5hotphos$fin_res_metric2,  mu = mean(FQD5blank$fin_res_metric2))
# FQD4 HotPhos sample vs. FQD5 HotPhos sample
t.test(FQD5hotphos$fin_res_metric2, mu = mean(FQD4hotphos$fin_res_metric2))
# FQD4 POR sample vs. FQD5 POR sample
t.test(FQD5blank$fin_res_metric2, mu = mean(FQD4blank$fin_res_metric2))
population_mean = mean(FQD4hotphos$fin_res_metric2)
population_sd = sd(FQD4hotphos$fin_res_metric2)
x<- seq(-4, 4, length = 1000)*population_sd + population_mean
y<- dnorm(x, population_mean, population_sd)
lower_bound <- population_mean - population_sd
upper_bound <- population_mean + population_sd
plot(x, y, type="n", xlab = "Fin_Res_Metric", ylab = "", main = "FQD4 HotPhos Distribution", axes = FALSE)
lines(x, y)
bounds_filter <- x >= lower_bound & x <= upper_bound
x_within_bounds <- x[bounds_filter]
y_within_bounds <- y[bounds_filter]
x_polygon <- c(lower_bound, x_within_bounds, upper_bound)
y_polygon <- c(0, y_within_bounds, 0)
#polygon(x_polygon, y_polygon, col = "red")
probability_within_bounds <- pnorm(upper_bound, population_mean, population_sd) - pnorm(lower_bound, population_mean, population_sd)
text <- paste("p(", lower_bound, "< height <", upper_bound, ") =", signif(probability_within_bounds, digits = 3))
#mtext(text)
sd_axis_bounds = 5
axis_bounds <- seq(-sd_axis_bounds * population_sd + population_mean, sd_axis_bounds * population_sd + population_mean, by = population_sd)
axis(side = 1, at = axis_bounds, pos = 0)
population_mean = mean(FQD4hotphos$fin_res_metric2)
population_sd = sd(FQD4hotphos$fin_res_metric2)
df = length(FQD4hotphos$fin_res_metric2) - 1
x<- seq(-4, 4, length = 1000)*population_sd + population_mean
y<- dt(x, df = df)
lower_bound <- population_mean - population_sd
upper_bound <- population_mean + population_sd
plot(x, y, type="n", xlab = "Fin_Res_Metric", ylab = "", main = "FQD4 HotPhos Distribution", axes = FALSE)
lines(x, y)
bounds_filter <- x >= lower_bound & x <= upper_bound
x_within_bounds <- x[bounds_filter]
y_within_bounds <- y[bounds_filter]
x_polygon <- c(lower_bound, x_within_bounds, upper_bound)
y_polygon <- c(0, y_within_bounds, 0)
#polygon(x_polygon, y_polygon, col = "red")
probability_within_bounds <- pnorm(upper_bound, population_mean, population_sd) - pnorm(lower_bound, population_mean, population_sd)
text <- paste("p(", lower_bound, "< height <", upper_bound, ") =", signif(probability_within_bounds, digits = 3))
#mtext(text)
sd_axis_bounds = 5
axis_bounds <- seq(-sd_axis_bounds * population_sd + population_mean, sd_axis_bounds * population_sd + population_mean, by = population_sd)
axis(side = 1, at = axis_bounds, pos = 0)
t.test(FQD4$fin_res_metric2~FQD4$X14HP_ExtendedHotPhos)
t.test(FQD5$fin_res_metric2~FQD5$X14HP_ExtendedHotPhos)
t.test(FQD4hotphos$fin_res_metric2,FQD4blank$fin_res_metric2)
sd(FQD4hotphos$fin_res_metric2)
t.test(FQD4$fin_res_metric2~FQD4$X14HP_ExtendedHotPhos)
t.test(FQD5$fin_res_metric2~FQD5$X14HP_ExtendedHotPhos)
t.test(FQD4hotphos$fin_res_metric2,FQD4blank$fin_res_metric2)
var(FQD4hotphos$fin_res_metric2)
t.test(FQD4$fin_res_metric2~FQD4$X14HP_ExtendedHotPhos)
t.test(FQD5$fin_res_metric2~FQD5$X14HP_ExtendedHotPhos)
t.test(FQD4hotphos$fin_res_metric2,FQD4blank$fin_res_metric2)
sqrt(var(FQD4hotphos$fin_res_metric2)/length(FQD4hotphos$fin_res_metric2) + var(FQD4blank$fin_res_metric2)/length(FQD4blank$fin_res_metric2))
t.test(FQD4$fin_res_metric2~FQD4$X14HP_ExtendedHotPhos)
t.test(FQD5$fin_res_metric2~FQD5$X14HP_ExtendedHotPhos)
t.test(FQD4hotphos$fin_res_metric2,FQD4blank$fin_res_metric2)
sqrt(var(FQD4hotphos$fin_res_metric2)/length(FQD4hotphos$fin_res_metric2) + var(FQD4blank$fin_res_metric2)/length(FQD4blank$fin_res_metric2))
sqrt(var(FQD5hotphos$fin_res_metric2)/length(FQD5hotphos$fin_res_metric2) + var(FQD5blank$fin_res_metric2)/length(FQD5blank$fin_res_metric2))
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/WFTAnalysis/")
getwd()
# Pull csv file and create wft df
wft <- read.csv("WFT.csv")
# Change column names for easier calls
colnames(wft)[3:7] <- c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly")
# Convert wft yields to percentage values
wft$wft8to24 <- wft$wft8to24*100
wft$wft22to24 <- wft$wft22to24*100
# Create USwft df for only US wafers
USwft <- wft[wft$FAMILY_CODE == "US",]
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/WFTAnalysis/")
getwd()
# Pull csv file and create wft df
wft <- read.csv("WFT.csv")
# Change column names for easier calls
colnames(wft)[3:7] <- c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly")
# Convert wft yields to percentage values
wft$wft8to24 <- wft$wft8to24*100
wft$wft22to24 <- wft$wft22to24*100
# Create USwft df for only US wafers
USwft <- wft[wft$FAMILY_CODE == "US",]
library(car)
library(reshape2)
library(ggplot2)
library(sandwich)
library(stargazer)
library(lmtest)
# Scatter Plot Matrix
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly, data = wft)
hist(log(wft$fin_res_metric2))
# Correlation Table
cor(wft[c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly", "fin_res_metric2")],
use = "complete.obs")
# Create model for 8-24c yield vs. only dg and sail yield.
model1 <- lm(wft8to24 ~ dgvmax+sailvmax, data = wft)
# Residuals-Fitted Values plot (Zero Conditional Mean)
plot(model1, 1)
# Scale-Location plot (Homoskedasticity)
plot(model1, 3)
# Breusch-Pagan Test for Homoskedasticity
bptest(model1)
# Q-Q Plot (Normality of Residuals)
plot(model1, 2)
# Shapiro-Wilk test of normality
shapiro.test(model1$residuals)
# Histogram of Residuals
hist(model1$residuals)
# Residuals-Leverage plot
plot(model1, 5) # No problem with Cook's distance
# a general rule is that if 1 % (or more) data points have standardized residuals > 2.5, the model contains too much error. If 5% (or more) of data points have residuals > 2, the model has too much error and represents our data poorly.
a <- rstudent(model1)
b <- a[a < -3]
# Create model for 8-24c yield vs. only dg and sail yield.
model1 <- lm(wft8to24 ~ dgvmax+sailvmax, data = wft)
# Residuals-Fitted Values plot (Zero Conditional Mean)
plot(model1, 1)
# Scale-Location plot (Homoskedasticity)
plot(model1, 3)
# Breusch-Pagan Test for Homoskedasticity
bptest(model1)
# Q-Q Plot (Normality of Residuals)
plot(model1, 2)
# Shapiro-Wilk test of normality
shapiro.test(model1$residuals)
# Histogram of Residuals
hist(model1$residuals)
# Residuals-Leverage plot
plot(model1, 5) # No problem with Cook's distance
# a general rule is that if 1 % (or more) data points have standardized residuals > 2.5, the model contains too much error. If 5% (or more) of data points have residuals > 2, the model has too much error and represents our data poorly.
a <- rstudent(model1)
model1$coefficients
b <- a[a < -3]
# Create model for 8-24c yield vs. only dg and sail yield.
model1 <- lm(wft8to24 ~ dgvmax+sailvmax, data = wft)
# Residuals-Fitted Values plot (Zero Conditional Mean)
plot(model1, 1)
# Scale-Location plot (Homoskedasticity)
plot(model1, 3)
# Breusch-Pagan Test for Homoskedasticity
bptest(model1)
# Q-Q Plot (Normality of Residuals)
plot(model1, 2)
# Shapiro-Wilk test of normality
shapiro.test(model1$residuals)
# Histogram of Residuals
hist(model1$residuals)
# Residuals-Leverage plot
plot(model1, 5) # No problem with Cook's distance
# a general rule is that if 1 % (or more) data points have standardized residuals > 2.5, the model contains too much error. If 5% (or more) of data points have residuals > 2, the model has too much error and represents our data poorly.
a <- rstudent(model1)
model1$summary
b <- a[a < -3]
# Create model for 8-24c yield vs. only dg and sail yield.
model1 <- lm(wft8to24 ~ dgvmax+sailvmax, data = wft)
# Residuals-Fitted Values plot (Zero Conditional Mean)
plot(model1, 1)
# Scale-Location plot (Homoskedasticity)
plot(model1, 3)
# Breusch-Pagan Test for Homoskedasticity
bptest(model1)
# Q-Q Plot (Normality of Residuals)
plot(model1, 2)
# Shapiro-Wilk test of normality
shapiro.test(model1$residuals)
# Histogram of Residuals
hist(model1$residuals)
# Residuals-Leverage plot
plot(model1, 5) # No problem with Cook's distance
# a general rule is that if 1 % (or more) data points have standardized residuals > 2.5, the model contains too much error. If 5% (or more) of data points have residuals > 2, the model has too much error and represents our data poorly.
a <- rstudent(model1)
summary(model1)
b <- a[a < -3]
# Create model for 8-24c yield vs. only dg and sail yield.
model1 <- lm(wft8to24 ~ dgvmax+sailvmax, data = wft)
# Residuals-Fitted Values plot (Zero Conditional Mean)
plot(model1, 1)
# Scale-Location plot (Homoskedasticity)
plot(model1, 3)
# Breusch-Pagan Test for Homoskedasticity
bptest(model1)
# Q-Q Plot (Normality of Residuals)
plot(model1, 2)
# Shapiro-Wilk test of normality
shapiro.test(model1$residuals)
# Histogram of Residuals
hist(model1$residuals)
# Residuals-Leverage plot
plot(model1, 5) # No problem with Cook's distance
# a general rule is that if 1 % (or more) data points have standardized residuals > 2.5, the model contains too much error. If 5% (or more) of data points have residuals > 2, the model has too much error and represents our data poorly.
a <- rstudent(model1)
summary(model1)
b <- a[a < -3]
model1.5<- lm(wft8to24 ~ dgvmax, data = wft)
summary(model1.5)
# Create model for 8-24c yield vs. only dg and sail yield.
model1 <- lm(wft8to24 ~ dgvmax+sailvmax, data = wft)
# Residuals-Fitted Values plot (Zero Conditional Mean)
plot(model1, 1)
# Scale-Location plot (Homoskedasticity)
plot(model1, 3)
# Breusch-Pagan Test for Homoskedasticity
bptest(model1)
# Q-Q Plot (Normality of Residuals)
plot(model1, 2)
# Shapiro-Wilk test of normality
shapiro.test(model1$residuals)
# Histogram of Residuals
hist(model1$residuals)
# Residuals-Leverage plot
plot(model1, 5) # No problem with Cook's distance
# a general rule is that if 1 % (or more) data points have standardized residuals > 2.5, the model contains too much error. If 5% (or more) of data points have residuals > 2, the model has too much error and represents our data poorly.
a <- rstudent(model1)
summary(model1)
b <- a[a < -3]
model1.5<- lm(wft8to24 ~ dgvmax, data = wft)
summary(model1.5)
plot(wft$dgvmax, wft$wft8to24)
View(wft)
View(wft)
model <- lm(wft8to24 ~ dgvmax+sailvmax+sailvmin_ly+fin_res_metric2, data = wft)
plot(model)
model$coefficients
sd(wft$wft8to24)
summary(model)$adj.r.square
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("LotLevel8-24C.csv")
View(data)
data <- read.csv("LotLevel8-24C.csv")
modelLL <- lm(WFT_Yield~DG_Yield+Sail_Yield, data = data)
data <- read.csv("LotLevel8-24C.csv")
modelLL <- lm(WFT_Yield~DG_Yield+Sail_Yield, data = data)
plot(modelLL)
data <- read.csv("LotLevel8-24C.csv")
modelLL <- lm(WFT_Yield~DG_Yield+Sail_Yield, data = data)
plot(modelLL)
summary(modelLL)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/WFTAnalysis/")
getwd()
# Pull csv file and create wft df
wft <- read.csv("WFT.csv")
# Change column names for easier calls
colnames(wft)[3:7] <- c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly")
# Convert wft yields to percentage values
wft$wft8to24 <- wft$wft8to24*100
wft$wft22to24 <- wft$wft22to24*100
# Create USwft df for only US wafers
USwft <- wft[wft$FAMILY_CODE == "US",]
library(car)
library(reshape2)
library(ggplot2)
library(sandwich)
library(stargazer)
library(lmtest)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/WFTAnalysis/")
getwd()
# Pull csv file and create wft df
wft <- read.csv("WFT.csv")
# Change column names for easier calls
colnames(wft)[3:7] <- c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly")
# Convert wft yields to percentage values
wft$wft8to24 <- wft$wft8to24*100
wft$wft22to24 <- wft$wft22to24*100
# Create USwft df for only US wafers
USwft <- wft[wft$FAMILY_CODE == "US",]
library(car)
library(reshape2)
library(ggplot2)
library(sandwich)
library(stargazer)
library(lmtest)
# Scatter Plot Matrix
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly, data = wft)
hist(log(wft$fin_res_metric2))
# Correlation Table
cor(wft[c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly", "fin_res_metric2")],
use = "complete.obs")
# Create model for 8-24c yield vs. only dg and sail yield.
model1 <- lm(wft8to24 ~ dgvmax+sailvmax, data = wft)
# Residuals-Fitted Values plot (Zero Conditional Mean)
plot(model1, 1)
# Scale-Location plot (Homoskedasticity)
plot(model1, 3)
# Breusch-Pagan Test for Homoskedasticity
bptest(model1)
# Q-Q Plot (Normality of Residuals)
plot(model1, 2)
# Shapiro-Wilk test of normality
shapiro.test(model1$residuals)
# Histogram of Residuals
hist(model1$residuals)
# Residuals-Leverage plot
plot(model1, 5) # No problem with Cook's distance
# a general rule is that if 1 % (or more) data points have standardized residuals > 2.5, the model contains too much error. If 5% (or more) of data points have residuals > 2, the model has too much error and represents our data poorly.
a <- rstudent(model1)
summary(model1)
b <- a[a < -3]
model1.5<- lm(wft8to24 ~ dgvmax, data = wft)
summary(model1.5)
plot(wft$dgvmax, wft$wft8to24)
data <- read.csv("LotLevel8-24C.csv")
modelLL <- lm(WFT_Yield~DG_Yield+Sail_Yield, data = data)
plot(modelLL)
summary(modelLL)
plot(data$WFT_Yield, data$DG_Yield)
data <- read.csv("LotLevel8-24C.csv")
modelLL <- lm(WFT_Yield~DG_Yield+Sail_Yield, data = data)
plot(modelLL)
summary(modelLL)
plot(data$DG_Yield, data$WFT_Yield)
data <- read.csv("LotLevel8-24C.csv")
modelLL <- lm(WFT_Yield~DG_Yield+Sail_Yield, data = data)
plot(modelLL)
summary(modelLL)
plot(data$DG_Yield, data$WFT_Yield)
plot(data$Sail_Yield, data$WFT_Yield)
# Scatter Plot Matrix
scatterplotMatrix(~wft8to24+wft22to24+dgvmax+sailvmax+sailvmin_ly, data = wft)
hist(log(wft$fin_res_metric2))
# Correlation Table
cor(wft[c("wft8to24", "wft22to24", "dgvmax", "sailvmax", "sailvmin_ly", "fin_res_metric2")],
use = "complete.obs")
# Create model for 8-24c yield vs. only dg and sail yield.
model1 <- lm(wft8to24 ~ dgvmax+sailvmax, data = wft)
# Residuals-Fitted Values plot (Zero Conditional Mean)
plot(model1, 1)
# Scale-Location plot (Homoskedasticity)
plot(model1, 3)
# Breusch-Pagan Test for Homoskedasticity
bptest(model1)
# Q-Q Plot (Normality of Residuals)
plot(model1, 2)
# Shapiro-Wilk test of normality
shapiro.test(model1$residuals)
# Histogram of Residuals
hist(model1$residuals)
# Residuals-Leverage plot
plot(model1, 5) # No problem with Cook's distance
# a general rule is that if 1 % (or more) data points have standardized residuals > 2.5, the model contains too much error. If 5% (or more) of data points have residuals > 2, the model has too much error and represents our data poorly.
a <- rstudent(model1)
summary(model1)
b <- a[a < -3]
model1.5<- lm(wft8to24 ~ dgvmax, data = wft)
summary(model1.5)
plot(wft$dgvmax, wft$wft8to24)
model <- lm(wft8to24 ~ dgvmax+sailvmax+sailvmin_ly+fin_res_metric2, data = wft)
plot(model)
model$coefficients
sd(wft$wft8to24)
summary(model)$adj.r.square
data <- read.csv("LotLevel8-24C.csv")
modelLL <- lm(WFT_Yield~DG_Yield+Sail_Yield, data = data)
modela <- lm(WFT_Yield~DG_Yield, data = data)
plot(modelLL)
summary(modelLL)
summary(modela)
plot(data$DG_Yield, data$WFT_Yield)
plot(data$Sail_Yield, data$WFT_Yield)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("LotLevel8-24C.csv")
modelLL <- lm(WFT_Yield~DG_Yield+Sail_Yield, data = data)
modela <- lm(WFT_Yield~DG_Yield, data = data)
plot(modelLL)
summary(modelLL)
summary(modela)
plot(data$DG_Yield, data$WFT_Yield)
plot(data$Sail_Yield, data$WFT_Yield)
View(data)
